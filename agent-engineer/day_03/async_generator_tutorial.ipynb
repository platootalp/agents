{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异步编程与生成器全面教程\n",
    "\n",
    "本教程涵盖Python中的异步编程和生成器的核心概念与实践应用。\n",
    "\n",
    "## 目录\n",
    "1. [生成器基础](#生成器基础)\n",
    "2. [生成器高级应用](#生成器高级应用)\n",
    "3. [异步编程基础](#异步编程基础)\n",
    "4. [异步编程进阶](#异步编程进阶)\n",
    "5. [异步生成器](#异步生成器)\n",
    "6. [实战案例](#实战案例)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 生成器基础 {#生成器基础}\n",
    "\n",
    "### 1.1 什么是生成器？\n",
    "\n",
    "生成器是一种特殊的迭代器，使用 `yield` 关键字来返回值，能够暂停和恢复执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础生成器示例\n",
    "def simple_generator():\n",
    "    \"\"\"最简单的生成器示例\"\"\"\n",
    "    print(\"开始执行\")\n",
    "    yield 1\n",
    "    print(\"继续执行\")\n",
    "    yield 2\n",
    "    print(\"最后执行\")\n",
    "    yield 3\n",
    "\n",
    "# 创建生成器对象\n",
    "gen = simple_generator()\n",
    "print(f\"生成器对象: {gen}\")\n",
    "print(f\"类型: {type(gen)}\")\n",
    "\n",
    "# 逐步获取值\n",
    "print(\"\\n--- 开始迭代 ---\")\n",
    "print(f\"第一次调用: {next(gen)}\")\n",
    "print(f\"第二次调用: {next(gen)}\")\n",
    "print(f\"第三次调用: {next(gen)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 生成器表达式\n",
    "\n",
    "类似列表推导式，但使用圆括号，更节省内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列表推导式 vs 生成器表达式\n",
    "import sys\n",
    "\n",
    "# 列表推导式 - 立即生成所有元素\n",
    "list_comp = [x**2 for x in range(10000)]\n",
    "print(f\"列表推导式内存占用: {sys.getsizeof(list_comp)} bytes\")\n",
    "\n",
    "# 生成器表达式 - 惰性计算\n",
    "gen_exp = (x**2 for x in range(10000))\n",
    "print(f\"生成器表达式内存占用: {sys.getsizeof(gen_exp)} bytes\")\n",
    "\n",
    "# 使用生成器表达式\n",
    "print(f\"\\n前5个平方数: {list(x for i, x in enumerate(gen_exp) if i < 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 斐波那契数列生成器\n",
    "\n",
    "经典的生成器应用案例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前10个斐波那契数:\n",
      "0 1 1 2 3 5 8 13 21 34 \n",
      "\n",
      "前15个斐波那契数列表: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377]\n"
     ]
    }
   ],
   "source": [
    "def fibonacci(n):\n",
    "    \"\"\"生成前n个斐波那契数\"\"\"\n",
    "    a, b = 0, 1\n",
    "    count = 0\n",
    "    while count < n:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        count += 1\n",
    "\n",
    "# 生成前10个斐波那契数\n",
    "print(\"前10个斐波那契数:\")\n",
    "for num in fibonacci(10):\n",
    "    print(num, end=' ')\n",
    "    \n",
    "# 使用列表转换\n",
    "print(f\"\\n\\n前15个斐波那契数列表: {list[int](fibonacci(15))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成器高级应用 {#生成器高级应用}\n",
    "\n",
    "### 2.1 生成器的send()方法\n",
    "\n",
    "生成器不仅可以产出值，还可以接收值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object echo_generator at 0x10d46d220>\n",
      "<class 'generator'>\n",
      "生成器启动\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "收到: Hello\n",
      "收到: World\n",
      "收到: 42\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def echo_generator():\n",
    "    \"\"\"可以接收值的生成器\"\"\"\n",
    "    print(\"生成器启动\")\n",
    "    while True:\n",
    "        received = yield\n",
    "        if received is None:\n",
    "            break\n",
    "        print(f\"收到: {received}\")\n",
    "        \n",
    "# 使用示例\n",
    "gen = echo_generator()\n",
    "print(gen)\n",
    "print(type(gen))\n",
    "# next(gen)  # 启动生成器\n",
    "gen.send(None) # 启动生成器\n",
    "gen.send(\"Hello\")\n",
    "gen.send(\"World\")\n",
    "gen.send(42)\n",
    "gen.close()  # 关闭生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 生产者-消费者模式\n",
    "\n",
    "使用生成器实现经典的生产者-消费者模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer():\n",
    "    \"\"\"消费者生成器\"\"\"\n",
    "    r = ''\n",
    "    while True:\n",
    "        n = yield r\n",
    "        if not n:\n",
    "            return\n",
    "        print(f'[消费者] 正在消费 {n}...')\n",
    "        r = '200 OK'\n",
    "\n",
    "def produce(c):\n",
    "    \"\"\"生产者函数\"\"\"\n",
    "    c.send(None)  # 启动生成器\n",
    "    n = 0\n",
    "    while n < 5:\n",
    "        n = n + 1\n",
    "        print(f'[生产者] 正在生产 {n}...')\n",
    "        r = c.send(n)\n",
    "        print(f'[生产者] 消费者返回: {r}')\n",
    "    c.close()\n",
    "\n",
    "# 执行\n",
    "print(\"=== 生产者-消费者模式演示 ===\")\n",
    "c = consumer()\n",
    "produce(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 yield from 语法\n",
    "\n",
    "`yield from` 用于委托给另一个生成器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_generator():\n",
    "    \"\"\"子生成器\"\"\"\n",
    "    yield \"子生成器: A\"\n",
    "    yield \"子生成器: B\"\n",
    "    return \"子生成器完成\"\n",
    "\n",
    "def delegating_generator():\n",
    "    \"\"\"委托生成器\"\"\"\n",
    "    yield \"委托生成器开始\"\n",
    "    result = yield from sub_generator()\n",
    "    print(f\"收到返回值: {result}\")\n",
    "    yield \"委托生成器结束\"\n",
    "\n",
    "# 使用\n",
    "for value in delegating_generator():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 流式数据处理\n",
    "\n",
    "生成器非常适合处理大型数据流。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_large_file(file_path, chunk_size=1024):\n",
    "    \"\"\"逐块读取大文件\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "\n",
    "def filter_lines(lines, keyword):\n",
    "    \"\"\"过滤包含关键字的行\"\"\"\n",
    "    for line in lines:\n",
    "        if keyword in line:\n",
    "            yield line\n",
    "\n",
    "def process_numbers(numbers):\n",
    "    \"\"\"处理数字流\"\"\"\n",
    "    for num in numbers:\n",
    "        if num % 2 == 0:\n",
    "            yield num * 2\n",
    "\n",
    "# 演示数字流处理\n",
    "numbers = range(20)\n",
    "processed = process_numbers(numbers)\n",
    "print(\"处理后的偶数（x2）:\", list(processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 异步编程基础 {#异步编程基础}\n",
    "\n",
    "### 3.1 协程与async/await\n",
    "\n",
    "Python 3.5+ 引入了 `async/await` 语法来简化异步编程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def hello_world():\n",
    "    \"\"\"最简单的协程\"\"\"\n",
    "    print(\"Hello\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"World\")\n",
    "\n",
    "# 执行协程\n",
    "print(\"=== 基础协程示例 ===\")\n",
    "await hello_world()  # 在 Jupyter 中可以直接 await"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 并发执行多个协程\n",
    "\n",
    "使用 `asyncio.gather()` 并发执行多个协程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def task(name, delay):\n",
    "    \"\"\"模拟异步任务\"\"\"\n",
    "    print(f\"任务 {name} 开始\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"任务 {name} 完成（耗时 {delay}s）\")\n",
    "    return f\"结果-{name}\"\n",
    "\n",
    "# 串行执行（同步方式）\n",
    "print(\"=== 串行执行 ===\")\n",
    "start = time.time()\n",
    "await task(\"A\", 2)\n",
    "await task(\"B\", 1)\n",
    "await task(\"C\", 1)\n",
    "print(f\"串行总耗时: {time.time() - start:.2f}s\\n\")\n",
    "\n",
    "# 并发执行（异步方式）\n",
    "print(\"=== 并发执行 ===\")\n",
    "start = time.time()\n",
    "results = await asyncio.gather(\n",
    "    task(\"A\", 2),\n",
    "    task(\"B\", 1),\n",
    "    task(\"C\", 1)\n",
    ")\n",
    "print(f\"并发总耗时: {time.time() - start:.2f}s\")\n",
    "print(f\"返回结果: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 异步上下文管理器\n",
    "\n",
    "使用 `async with` 管理异步资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "class AsyncResource:\n",
    "    \"\"\"异步资源管理器\"\"\"\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        print(\"获取资源...\")\n",
    "        await asyncio.sleep(0.5)\n",
    "        print(\"资源已获取\")\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        print(\"释放资源...\")\n",
    "        await asyncio.sleep(0.5)\n",
    "        print(\"资源已释放\")\n",
    "    \n",
    "    async def do_work(self):\n",
    "        print(\"正在工作...\")\n",
    "        await asyncio.sleep(1)\n",
    "        print(\"工作完成\")\n",
    "\n",
    "# 使用异步上下文管理器\n",
    "async with AsyncResource() as resource:\n",
    "    await resource.do_work()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 异步编程进阶 {#异步编程进阶}\n",
    "\n",
    "### 4.1 异步HTTP请求\n",
    "\n",
    "使用 `aiohttp` 进行高效的并发HTTP请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "async def fetch(session, url):\n",
    "    \"\"\"获取单个URL的数据\"\"\"\n",
    "    print(f\"正在请求: {url}\")\n",
    "    try:\n",
    "        async with session.get(url, timeout=10) as response:\n",
    "            data = await response.json()\n",
    "            print(f\"完成请求: {url} (状态: {response.status})\")\n",
    "            return {\"url\": url, \"data\": data, \"status\": response.status}\n",
    "    except Exception as e:\n",
    "        print(f\"请求失败: {url} - {e}\")\n",
    "        return {\"url\": url, \"error\": str(e)}\n",
    "\n",
    "async def batch_fetch(urls):\n",
    "    \"\"\"批量获取多个URL的数据\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "# 测试批量请求\n",
    "urls = [\n",
    "    \"https://api.github.com/users/github\",\n",
    "    \"https://api.github.com/users/python\",\n",
    "    \"https://api.github.com/users/microsoft\"\n",
    "]\n",
    "\n",
    "print(\"=== 异步HTTP请求示例 ===\")\n",
    "start = time.time()\n",
    "results = await batch_fetch(urls)\n",
    "print(f\"\\n总耗时: {time.time() - start:.2f}s\")\n",
    "print(f\"\\n成功请求数: {sum(1 for r in results if 'data' in r)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 任务控制与取消\n",
    "\n",
    "使用 `asyncio.Task` 进行任务管理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def long_running_task(name, duration):\n",
    "    \"\"\"长时间运行的任务\"\"\"\n",
    "    try:\n",
    "        print(f\"任务 {name} 开始 (预计 {duration}s)\")\n",
    "        for i in range(duration):\n",
    "            await asyncio.sleep(1)\n",
    "            print(f\"任务 {name}: {i+1}s\")\n",
    "        print(f\"任务 {name} 完成\")\n",
    "        return f\"结果-{name}\"\n",
    "    except asyncio.CancelledError:\n",
    "        print(f\"任务 {name} 被取消\")\n",
    "        raise\n",
    "\n",
    "# 创建任务\n",
    "task1 = asyncio.create_task(long_running_task(\"A\", 3))\n",
    "task2 = asyncio.create_task(long_running_task(\"B\", 5))\n",
    "\n",
    "# 等待2秒后取消任务2\n",
    "await asyncio.sleep(2)\n",
    "print(\"\\n--- 取消任务B ---\")\n",
    "task2.cancel()\n",
    "\n",
    "# 等待所有任务（包括已取消的）\n",
    "results = await asyncio.gather(task1, task2, return_exceptions=True)\n",
    "print(f\"\\n结果: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 信号量与限流\n",
    "\n",
    "使用信号量控制并发数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def download_file(semaphore, file_id):\n",
    "    \"\"\"模拟下载文件（限制并发数）\"\"\"\n",
    "    async with semaphore:  # 获取信号量\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] 开始下载文件 {file_id}\")\n",
    "        await asyncio.sleep(2)  # 模拟下载耗时\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] 完成下载文件 {file_id}\")\n",
    "        return f\"文件-{file_id}\"\n",
    "\n",
    "async def download_all_files(file_count, max_concurrent):\n",
    "    \"\"\"下载所有文件，限制最大并发数\"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    tasks = [download_file(semaphore, i) for i in range(file_count)]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "# 下载10个文件，最多同时下载3个\n",
    "print(\"=== 限流下载示例（最多3个并发） ===\")\n",
    "start = time.time()\n",
    "results = await download_all_files(file_count=10, max_concurrent=3)\n",
    "print(f\"\\n总耗时: {time.time() - start:.2f}s\")\n",
    "print(f\"下载完成: {len(results)} 个文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 异步队列\n",
    "\n",
    "使用 `asyncio.Queue` 实现生产者-消费者模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def producer(queue, producer_id, item_count):\n",
    "    \"\"\"生产者\"\"\"\n",
    "    for i in range(item_count):\n",
    "        item = f\"P{producer_id}-Item{i}\"\n",
    "        await queue.put(item)\n",
    "        print(f\"[生产者{producer_id}] 生产: {item}\")\n",
    "        await asyncio.sleep(random.uniform(0.1, 0.5))\n",
    "    print(f\"[生产者{producer_id}] 完成\")\n",
    "\n",
    "async def consumer(queue, consumer_id):\n",
    "    \"\"\"消费者\"\"\"\n",
    "    while True:\n",
    "        item = await queue.get()\n",
    "        if item is None:  # 终止信号\n",
    "            queue.task_done()\n",
    "            break\n",
    "        print(f\"[消费者{consumer_id}] 消费: {item}\")\n",
    "        await asyncio.sleep(random.uniform(0.2, 0.8))\n",
    "        queue.task_done()\n",
    "    print(f\"[消费者{consumer_id}] 完成\")\n",
    "\n",
    "async def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    queue = asyncio.Queue(maxsize=5)  # 限制队列大小\n",
    "    \n",
    "    # 启动2个生产者和3个消费者\n",
    "    producers = [\n",
    "        asyncio.create_task(producer(queue, i, 5)) \n",
    "        for i in range(2)\n",
    "    ]\n",
    "    consumers = [\n",
    "        asyncio.create_task(consumer(queue, i)) \n",
    "        for i in range(3)\n",
    "    ]\n",
    "    \n",
    "    # 等待所有生产者完成\n",
    "    await asyncio.gather(*producers)\n",
    "    \n",
    "    # 等待队列清空\n",
    "    await queue.join()\n",
    "    \n",
    "    # 发送终止信号给所有消费者\n",
    "    for _ in consumers:\n",
    "        await queue.put(None)\n",
    "    \n",
    "    # 等待所有消费者完成\n",
    "    await asyncio.gather(*consumers)\n",
    "\n",
    "print(\"=== 异步队列示例 ===\")\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 异步生成器 {#异步生成器}\n",
    "\n",
    "### 5.1 基础异步生成器\n",
    "\n",
    "结合异步编程和生成器的特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def async_counter(n):\n",
    "    \"\"\"异步计数器\"\"\"\n",
    "    for i in range(n):\n",
    "        await asyncio.sleep(0.5)\n",
    "        yield i\n",
    "\n",
    "# 使用异步生成器\n",
    "print(\"=== 异步生成器示例 ===\")\n",
    "async for num in async_counter(5):\n",
    "    print(f\"收到: {num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 异步数据流处理\n",
    "\n",
    "使用异步生成器处理实时数据流。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "async def fetch_data_stream(source_id, count):\n",
    "    \"\"\"模拟从数据源获取数据流\"\"\"\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(random.uniform(0.1, 0.5))\n",
    "        data = {\n",
    "            \"source\": source_id,\n",
    "            \"index\": i,\n",
    "            \"value\": random.randint(1, 100),\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        yield data\n",
    "\n",
    "async def process_stream(stream):\n",
    "    \"\"\"处理数据流\"\"\"\n",
    "    async for item in stream:\n",
    "        # 模拟数据处理\n",
    "        processed = {\n",
    "            **item,\n",
    "            \"processed\": item[\"value\"] * 2,\n",
    "            \"status\": \"ok\" if item[\"value\"] > 50 else \"low\"\n",
    "        }\n",
    "        yield processed\n",
    "\n",
    "# 使用示例\n",
    "print(\"=== 异步数据流处理 ===\")\n",
    "stream = fetch_data_stream(\"sensor-1\", 5)\n",
    "processed_stream = process_stream(stream)\n",
    "\n",
    "async for data in processed_stream:\n",
    "    print(f\"数据: 值={data['value']}, 处理后={data['processed']}, 状态={data['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 合并多个异步流\n",
    "\n",
    "同时处理多个异步数据源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def sensor_data(sensor_id, count):\n",
    "    \"\"\"模拟传感器数据流\"\"\"\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(random.uniform(0.2, 0.8))\n",
    "        yield f\"[传感器{sensor_id}] 数据-{i}\"\n",
    "\n",
    "async def merge_streams(*streams):\n",
    "    \"\"\"合并多个异步流\"\"\"\n",
    "    # 为每个流创建迭代器\n",
    "    iterators = [stream.__aiter__() for stream in streams]\n",
    "    \n",
    "    # 创建任务获取每个流的下一个值\n",
    "    async def get_next(iterator, index):\n",
    "        try:\n",
    "            value = await iterator.__anext__()\n",
    "            return (index, value, False)\n",
    "        except StopAsyncIteration:\n",
    "            return (index, None, True)\n",
    "    \n",
    "    pending = {\n",
    "        asyncio.create_task(get_next(it, i)) \n",
    "        for i, it in enumerate(iterators)\n",
    "    }\n",
    "    \n",
    "    active_count = len(iterators)\n",
    "    \n",
    "    while active_count > 0:\n",
    "        done, pending = await asyncio.wait(\n",
    "            pending, \n",
    "            return_when=asyncio.FIRST_COMPLETED\n",
    "        )\n",
    "        \n",
    "        for task in done:\n",
    "            index, value, is_done = await task\n",
    "            \n",
    "            if not is_done:\n",
    "                yield value\n",
    "                # 为这个流创建新的任务\n",
    "                pending.add(\n",
    "                    asyncio.create_task(get_next(iterators[index], index))\n",
    "                )\n",
    "            else:\n",
    "                active_count -= 1\n",
    "\n",
    "# 使用示例\n",
    "print(\"=== 合并多个异步流 ===\")\n",
    "stream1 = sensor_data(1, 3)\n",
    "stream2 = sensor_data(2, 3)\n",
    "stream3 = sensor_data(3, 3)\n",
    "\n",
    "merged = merge_streams(stream1, stream2, stream3)\n",
    "async for data in merged:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 实战案例 {#实战案例}\n",
    "\n",
    "### 6.1 网页爬虫\n",
    "\n",
    "使用异步编程实现高效的网页爬虫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "\n",
    "class AsyncWebCrawler:\n",
    "    \"\"\"异步网页爬虫\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent=5, timeout=10):\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.timeout = timeout\n",
    "        self.visited = set()\n",
    "        self.results = []\n",
    "    \n",
    "    async def fetch_page(self, session, url):\n",
    "        \"\"\"获取页面内容\"\"\"\n",
    "        if url in self.visited:\n",
    "            return None\n",
    "        \n",
    "        self.visited.add(url)\n",
    "        print(f\"正在爬取: {url}\")\n",
    "        \n",
    "        try:\n",
    "            async with session.get(url, timeout=self.timeout) as response:\n",
    "                content = await response.text()\n",
    "                result = {\n",
    "                    \"url\": url,\n",
    "                    \"status\": response.status,\n",
    "                    \"length\": len(content),\n",
    "                    \"content_type\": response.headers.get(\"content-type\", \"\")\n",
    "                }\n",
    "                self.results.append(result)\n",
    "                print(f\"完成: {url} (状态: {response.status}, 大小: {len(content)}字节)\")\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            print(f\"错误: {url} - {e}\")\n",
    "            return None\n",
    "    \n",
    "    async def crawl(self, urls):\n",
    "        \"\"\"爬取URL列表\"\"\"\n",
    "        semaphore = asyncio.Semaphore(self.max_concurrent)\n",
    "        \n",
    "        async def fetch_with_limit(url):\n",
    "            async with semaphore:\n",
    "                return await self.fetch_page(session, url)\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [fetch_with_limit(url) for url in urls]\n",
    "            await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# 使用示例\n",
    "urls = [\n",
    "    \"https://httpbin.org/delay/1\",\n",
    "    \"https://httpbin.org/delay/2\",\n",
    "    \"https://httpbin.org/status/200\",\n",
    "    \"https://httpbin.org/html\"\n",
    "]\n",
    "\n",
    "print(\"=== 异步网页爬虫示例 ===\")\n",
    "crawler = AsyncWebCrawler(max_concurrent=3)\n",
    "start = time.time()\n",
    "results = await crawler.crawl(urls)\n",
    "print(f\"\\n总耗时: {time.time() - start:.2f}s\")\n",
    "print(f\"成功爬取: {len(results)} 个页面\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 实时日志处理\n",
    "\n",
    "使用异步生成器实时处理日志文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "async def log_generator(log_count):\n",
    "    \"\"\"模拟日志生成器\"\"\"\n",
    "    levels = [\"INFO\", \"WARNING\", \"ERROR\", \"DEBUG\"]\n",
    "    messages = [\n",
    "        \"用户登录成功\",\n",
    "        \"数据库查询完成\",\n",
    "        \"缓存命中\",\n",
    "        \"API请求超时\",\n",
    "        \"内存使用率高\"\n",
    "    ]\n",
    "    \n",
    "    for i in range(log_count):\n",
    "        await asyncio.sleep(random.uniform(0.1, 0.5))\n",
    "        log = {\n",
    "            \"id\": i,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": random.choice(levels),\n",
    "            \"message\": random.choice(messages)\n",
    "        }\n",
    "        yield log\n",
    "\n",
    "async def filter_logs(log_stream, level=\"ERROR\"):\n",
    "    \"\"\"过滤特定级别的日志\"\"\"\n",
    "    async for log in log_stream:\n",
    "        if log[\"level\"] == level:\n",
    "            yield log\n",
    "\n",
    "async def analyze_logs(log_stream):\n",
    "    \"\"\"分析日志\"\"\"\n",
    "    stats = {\"INFO\": 0, \"WARNING\": 0, \"ERROR\": 0, \"DEBUG\": 0}\n",
    "    \n",
    "    async for log in log_stream:\n",
    "        stats[log[\"level\"]] += 1\n",
    "        print(f\"[{log['timestamp']}] {log['level']}: {log['message']}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# 使用示例\n",
    "print(\"=== 实时日志处理 ===\")\n",
    "log_stream = log_generator(10)\n",
    "stats = await analyze_logs(log_stream)\n",
    "print(f\"\\n日志统计: {stats}\")\n",
    "\n",
    "# 过滤ERROR日志\n",
    "print(\"\\n=== 仅显示ERROR日志 ===\")\n",
    "log_stream = log_generator(20)\n",
    "error_stream = filter_logs(log_stream, \"ERROR\")\n",
    "async for log in error_stream:\n",
    "    print(f\"[ERROR] {log['timestamp']}: {log['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 数据库批量操作\n",
    "\n",
    "使用异步编程优化数据库操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "# 模拟数据库操作\n",
    "class MockAsyncDB:\n",
    "    \"\"\"模拟异步数据库\"\"\"\n",
    "    \n",
    "    async def insert(self, table, data):\n",
    "        \"\"\"插入数据\"\"\"\n",
    "        await asyncio.sleep(0.1)  # 模拟IO延迟\n",
    "        return {\"id\": data.get(\"id\"), \"status\": \"inserted\"}\n",
    "    \n",
    "    async def query(self, table, condition):\n",
    "        \"\"\"查询数据\"\"\"\n",
    "        await asyncio.sleep(0.15)  # 模拟IO延迟\n",
    "        return {\"result\": [condition]}\n",
    "    \n",
    "    async def update(self, table, data):\n",
    "        \"\"\"更新数据\"\"\"\n",
    "        await asyncio.sleep(0.12)  # 模拟IO延迟\n",
    "        return {\"id\": data.get(\"id\"), \"status\": \"updated\"}\n",
    "\n",
    "async def batch_insert(db, records):\n",
    "    \"\"\"批量插入记录\"\"\"\n",
    "    tasks = [db.insert(\"users\", record) for record in records]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "async def batch_query(db, ids):\n",
    "    \"\"\"批量查询记录\"\"\"\n",
    "    tasks = [db.query(\"users\", {\"id\": id}) for id in ids]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# 使用示例\n",
    "db = MockAsyncDB()\n",
    "\n",
    "# 批量插入\n",
    "print(\"=== 批量插入数据 ===\")\n",
    "records = [{\"id\": i, \"name\": f\"用户{i}\", \"email\": f\"user{i}@example.com\"} for i in range(10)]\n",
    "start = time.time()\n",
    "insert_results = await batch_insert(db, records)\n",
    "print(f\"插入 {len(insert_results)} 条记录，耗时: {time.time() - start:.2f}s\")\n",
    "\n",
    "# 批量查询\n",
    "print(\"\\n=== 批量查询数据 ===\")\n",
    "ids = list(range(10))\n",
    "start = time.time()\n",
    "query_results = await batch_query(db, ids)\n",
    "print(f\"查询 {len(query_results)} 条记录，耗时: {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 文件处理管道\n",
    "\n",
    "组合生成器实现数据处理管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "\n",
    "async def read_json_lines(data_list):\n",
    "    \"\"\"模拟读取JSON行\"\"\"\n",
    "    for item in data_list:\n",
    "        await asyncio.sleep(0.1)\n",
    "        yield json.dumps(item)\n",
    "\n",
    "async def parse_json(line_stream):\n",
    "    \"\"\"解析JSON\"\"\"\n",
    "    async for line in line_stream:\n",
    "        try:\n",
    "            yield json.loads(line)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"解析错误: {e}\")\n",
    "\n",
    "async def filter_data(data_stream, min_value):\n",
    "    \"\"\"过滤数据\"\"\"\n",
    "    async for item in data_stream:\n",
    "        if item.get(\"value\", 0) >= min_value:\n",
    "            yield item\n",
    "\n",
    "async def transform_data(data_stream):\n",
    "    \"\"\"转换数据\"\"\"\n",
    "    async for item in data_stream:\n",
    "        transformed = {\n",
    "            \"id\": item.get(\"id\"),\n",
    "            \"value\": item.get(\"value\", 0) * 2,\n",
    "            \"category\": item.get(\"category\", \"unknown\").upper()\n",
    "        }\n",
    "        yield transformed\n",
    "\n",
    "async def aggregate_data(data_stream):\n",
    "    \"\"\"聚合数据\"\"\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    categories = {}\n",
    "    \n",
    "    async for item in data_stream:\n",
    "        total += item[\"value\"]\n",
    "        count += 1\n",
    "        category = item[\"category\"]\n",
    "        categories[category] = categories.get(category, 0) + 1\n",
    "    \n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"count\": count,\n",
    "        \"average\": total / count if count > 0 else 0,\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "# 使用示例\n",
    "print(\"=== 数据处理管道 ===\")\n",
    "data = [\n",
    "    {\"id\": 1, \"value\": 10, \"category\": \"a\"},\n",
    "    {\"id\": 2, \"value\": 25, \"category\": \"b\"},\n",
    "    {\"id\": 3, \"value\": 15, \"category\": \"a\"},\n",
    "    {\"id\": 4, \"value\": 5, \"category\": \"c\"},\n",
    "    {\"id\": 5, \"value\": 30, \"category\": \"b\"}\n",
    "]\n",
    "\n",
    "# 构建处理管道\n",
    "pipeline = read_json_lines(data)\n",
    "pipeline = parse_json(pipeline)\n",
    "pipeline = filter_data(pipeline, min_value=10)  # 过滤值>=10的数据\n",
    "pipeline = transform_data(pipeline)\n",
    "\n",
    "# 执行管道并聚合\n",
    "result = await aggregate_data(pipeline)\n",
    "print(f\"\\n聚合结果:\")\n",
    "print(f\"  总和: {result['total']}\")\n",
    "print(f\"  数量: {result['count']}\")\n",
    "print(f\"  平均值: {result['average']:.2f}\")\n",
    "print(f\"  分类统计: {result['categories']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 生成器优势\n",
    "- 内存效率：惰性计算，不需要一次性加载所有数据\n",
    "- 代码简洁：用yield简化复杂的迭代逻辑\n",
    "- 管道处理：可以组合多个生成器形成处理链\n",
    "\n",
    "### 异步编程优势\n",
    "- 高并发：单线程处理大量IO操作\n",
    "- 资源效率：避免线程开销\n",
    "- 代码清晰：async/await语法简洁直观\n",
    "\n",
    "### 最佳实践\n",
    "1. **生成器**：适用于大数据集、流式处理、无限序列\n",
    "2. **异步编程**：适用于IO密集型任务（网络请求、文件读写、数据库操作）\n",
    "3. **异步生成器**：结合两者优势，处理异步数据流\n",
    "4. **并发控制**：使用信号量限制并发数量\n",
    "5. **错误处理**：使用try-except和return_exceptions处理异常\n",
    "\n",
    "### 注意事项\n",
    "- 异步编程不适合CPU密集型任务（应使用多进程）\n",
    "- 生成器只能迭代一次\n",
    "- 异步函数必须在异步上下文中调用\n",
    "- 注意避免阻塞操作（如time.sleep，应使用asyncio.sleep）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资源\n",
    "\n",
    "- [Python asyncio 官方文档](https://docs.python.org/3/library/asyncio.html)\n",
    "- [PEP 492 - Coroutines with async and await syntax](https://www.python.org/dev/peps/pep-0492/)\n",
    "- [PEP 525 - Asynchronous Generators](https://www.python.org/dev/peps/pep-0525/)\n",
    "- [aiohttp 文档](https://docs.aiohttp.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
