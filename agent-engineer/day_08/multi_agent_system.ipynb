{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç”Ÿäº§çº§Multi-Agentç³»ç»Ÿå®ç°\n",
    "\n",
    "## ç³»ç»Ÿæ¦‚è¿°\n",
    "\n",
    "æœ¬Notebookå®ç°äº†ä¸€ä¸ªåŸºäºLangGraphçš„ç”Ÿäº§çº§Multi-Agentç³»ç»Ÿï¼Œç”¨äºè‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ã€‚ç³»ç»ŸåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š\n",
    "\n",
    "1. **LangGraphå·¥ä½œæµ**ï¼šåŒ…å«åˆ†æAgentã€å®‰å…¨Agentã€æŠ¥å‘ŠAgentçš„åä½œæµç¨‹\n",
    "2. **é€šä¿¡åè®®**ï¼šåŸºäºæ¶ˆæ¯é˜Ÿåˆ—çš„å¼‚æ­¥Agenté€šä¿¡\n",
    "3. **ä»»åŠ¡åˆ†é…ç®—æ³•**ï¼šåŸºäºèƒ½åŠ›çŸ©é˜µçš„æ™ºèƒ½è´Ÿè½½å‡è¡¡\n",
    "4. **åè°ƒæœºåˆ¶**ï¼šç®€åŒ–Raftç®—æ³•å®ç°é¢†å¯¼è€…é€‰ä¸¾å’ŒçŠ¶æ€åŒæ­¥\n",
    "5. **çŠ¶æ€å­˜å‚¨**ï¼šRedisé›†æˆå®ç°å·¥ä½œæµçŠ¶æ€æŒä¹…åŒ–\n",
    "\n",
    "## Javaç»éªŒè¿ç§»\n",
    "\n",
    "- **å·¥ä½œæµå¼•æ“**ï¼šActiviti/Camunda â†’ LangGraphçŠ¶æ€å›¾è®¾è®¡\n",
    "- **æ¶ˆæ¯ä¸­é—´ä»¶**ï¼šKafkaç”Ÿäº§è€…/æ¶ˆè´¹è€… â†’ Agenté€šä¿¡å±‚\n",
    "- **è´Ÿè½½å‡è¡¡**ï¼šRibbonç®—æ³• â†’ ä»»åŠ¡åˆ†é…ç­–ç•¥\n",
    "- **åˆ†å¸ƒå¼é”**ï¼šRedisson â†’ åè°ƒæœºåˆ¶å®ç°\n",
    "- **è¿æ¥æ± **ï¼šHikariCP â†’ Redisè¿æ¥ç®¡ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "!pip install langgraph langchain-openai redis asyncio aiohttp numpy pandas matplotlib protobuf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from typing import Dict, List, Optional, Any, TypedDict\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "from dataclasses import dataclass, asdict\n",
    "from enum import Enum\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ¶ˆæ¯é˜Ÿåˆ—å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageQueue:\n",
    "    \"\"\"åŸºäºå†…å­˜çš„æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆæ¨¡æ‹ŸKafkaï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, max_queue_size: int = 10000):\n",
    "        self.queues: Dict[str, List[Dict]] = {}\n",
    "        self.consumer_groups: Dict[str, Dict[str, int]] = {}\n",
    "        self.max_queue_size = max_queue_size\n",
    "        \n",
    "    async def produce(self, topic: str, data: Dict[str, Any], \n",
    "                     priority: int = 1) -> str:\n",
    "        \"\"\"ç”Ÿäº§æ¶ˆæ¯\"\"\"\n",
    "        if topic not in self.queues:\n",
    "            self.queues[topic] = []\n",
    "            \n",
    "        message_id = str(uuid.uuid4())\n",
    "        message = {\n",
    "            \"id\": message_id,\n",
    "            \"data\": data,\n",
    "            \"priority\": priority,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        \n",
    "        self.queues[topic].append(message)\n",
    "        # æŒ‰ä¼˜å…ˆçº§æ’åº\n",
    "        self.queues[topic].sort(key=lambda x: -x[\"priority\"])\n",
    "        \n",
    "        print(f\"[æ¶ˆæ¯é˜Ÿåˆ—] ç”Ÿäº§æ¶ˆæ¯åˆ°ä¸»é¢˜ {topic}: {message_id}\")\n",
    "        return message_id\n",
    "    \n",
    "    async def consume(self, topic: str, consumer_id: str) -> Optional[Dict]:\n",
    "        \"\"\"æ¶ˆè´¹æ¶ˆæ¯\"\"\"\n",
    "        if topic not in self.queues or not self.queues[topic]:\n",
    "            return None\n",
    "            \n",
    "        # åˆå§‹åŒ–æ¶ˆè´¹è€…ç»„\n",
    "        if topic not in self.consumer_groups:\n",
    "            self.consumer_groups[topic] = {}\n",
    "        \n",
    "        if consumer_id not in self.consumer_groups[topic]:\n",
    "            self.consumer_groups[topic][consumer_id] = 0\n",
    "            \n",
    "        offset = self.consumer_groups[topic][consumer_id]\n",
    "        \n",
    "        if offset >= len(self.queues[topic]):\n",
    "            return None\n",
    "            \n",
    "        message = self.queues[topic][offset]\n",
    "        self.consumer_groups[topic][consumer_id] = offset + 1\n",
    "        \n",
    "        print(f\"[æ¶ˆæ¯é˜Ÿåˆ—] æ¶ˆè´¹è€… {consumer_id} æ¶ˆè´¹æ¶ˆæ¯: {message['id']}\")\n",
    "        return message\n",
    "\n",
    "# æµ‹è¯•æ¶ˆæ¯é˜Ÿåˆ—\n",
    "async def test_message_queue():\n",
    "    mq = MessageQueue()\n",
    "    \n",
    "    # ç”Ÿäº§æµ‹è¯•æ¶ˆæ¯\n",
    "    msg_id = await mq.produce(\"test_topic\", {\"type\": \"test\", \"content\": \"Hello\"})\n",
    "    print(f\"ç”Ÿäº§çš„æ¶ˆæ¯ID: {msg_id}\")\n",
    "    \n",
    "    # æ¶ˆè´¹æ¶ˆæ¯\n",
    "    message = await mq.consume(\"test_topic\", \"test_consumer\")\n",
    "    if message:\n",
    "        print(f\"æ¶ˆè´¹çš„æ¶ˆæ¯: {message['id']}, æ•°æ®: {message['data']}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "await test_message_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. èƒ½åŠ›çŸ©é˜µä¸è´Ÿè½½å‡è¡¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapabilityMatrix:\n",
    "    \"\"\"Agentèƒ½åŠ›çŸ©é˜µ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # åˆå§‹åŒ–Agentèƒ½åŠ›é…ç½®\n",
    "        self.agents = {\n",
    "            \"analyzer\": {\n",
    "                \"structural_analysis\": 0.9,\n",
    "                \"complexity_calculation\": 0.8,\n",
    "                \"style_checking\": 0.7,\n",
    "                \"current_load\": 0.0\n",
    "            },\n",
    "            \"security\": {\n",
    "                \"sql_injection\": 0.95,\n",
    "                \"xss_detection\": 0.85,\n",
    "                \"hardcoded_secrets\": 0.9,\n",
    "                \"current_load\": 0.0\n",
    "            },\n",
    "            \"reporter\": {\n",
    "                \"result_aggregation\": 0.8,\n",
    "                \"report_generation\": 0.9,\n",
    "                \"format_beautification\": 0.7,\n",
    "                \"current_load\": 0.0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_task_requirements(self, code: str) -> Dict[str, float]:\n",
    "        \"\"\"åˆ†æä»£ç ä»»åŠ¡éœ€æ±‚\"\"\"\n",
    "        requirements = {}\n",
    "        code_lower = code.lower()\n",
    "        \n",
    "        # ç®€å•çš„è§„åˆ™åˆ†æ\n",
    "        if \"select\" in code_lower or \"insert\" in code_lower:\n",
    "            requirements[\"sql_injection\"] = 0.4\n",
    "            requirements[\"structural_analysis\"] = 0.3\n",
    "            requirements[\"complexity_calculation\"] = 0.3\n",
    "        elif \"eval(\" in code_lower or \"exec(\" in code_lower:\n",
    "            requirements[\"security\"] = 0.5\n",
    "            requirements[\"xss_detection\"] = 0.3\n",
    "            requirements[\"hardcoded_secrets\"] = 0.2\n",
    "        else:\n",
    "            requirements[\"structural_analysis\"] = 0.4\n",
    "            requirements[\"complexity_calculation\"] = 0.3\n",
    "            requirements[\"style_checking\"] = 0.3\n",
    "        \n",
    "        # å½’ä¸€åŒ–\n",
    "        total = sum(requirements.values())\n",
    "        if total > 0:\n",
    "            requirements = {k: v/total for k, v in requirements.items()}\n",
    "        \n",
    "        return requirements\n",
    "    \n",
    "    def select_best_agent(self, requirements: Dict[str, float]) -> str:\n",
    "        \"\"\"é€‰æ‹©æœ€é€‚åˆçš„Agent\"\"\"\n",
    "        best_agent = None\n",
    "        best_score = -1.0\n",
    "        \n",
    "        for agent_id, capabilities in self.agents.items():\n",
    "            # è®¡ç®—èƒ½åŠ›å¾—åˆ†\n",
    "            score = 0.0\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            for req, weight in requirements.items():\n",
    "                if req in capabilities:\n",
    "                    score += capabilities[req] * weight\n",
    "                    total_weight += weight\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                score /= total_weight\n",
    "            \n",
    "            # è´Ÿè½½æƒ©ç½š\n",
    "            load_penalty = 1.0 - capabilities[\"current_load\"]\n",
    "            final_score = score * load_penalty\n",
    "            \n",
    "            if final_score > best_score:\n",
    "                best_score = final_score\n",
    "                best_agent = agent_id\n",
    "        \n",
    "        return best_agent\n",
    "\n",
    "class LoadBalancer:\n",
    "    \"\"\"è´Ÿè½½å‡è¡¡å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.capability_matrix = CapabilityMatrix()\n",
    "        self.assignment_history = []\n",
    "    \n",
    "    def assign_task(self, task: Dict[str, Any]) -> str:\n",
    "        \"\"\"åˆ†é…ä»»åŠ¡ç»™Agent\"\"\"\n",
    "        code = task.get(\"code\", \"\")\n",
    "        requirements = self.capability_matrix.analyze_task_requirements(code)\n",
    "        \n",
    "        selected_agent = self.capability_matrix.select_best_agent(requirements)\n",
    "        \n",
    "        # æ›´æ–°è´Ÿè½½\n",
    "        self.capability_matrix.agents[selected_agent][\"current_load\"] += 0.1\n",
    "        \n",
    "        # è®°å½•åˆ†é…å†å²\n",
    "        self.assignment_history.append({\n",
    "            \"task_id\": task.get(\"id\", \"unknown\"),\n",
    "            \"assigned_agent\": selected_agent,\n",
    "            \"requirements\": requirements,\n",
    "            \"timestamp\": time.time()\n",
    "        })\n",
    "        \n",
    "        print(f\"[è´Ÿè½½å‡è¡¡å™¨] ä»»åŠ¡åˆ†é…: {task.get('id', 'unknown')} â†’ {selected_agent}\")\n",
    "        return selected_agent\n",
    "\n",
    "# æµ‹è¯•è´Ÿè½½å‡è¡¡\n",
    "def test_load_balancing():\n",
    "    lb = LoadBalancer()\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡\n",
    "    tasks = [\n",
    "        {\"id\": \"task_1\", \"code\": \"SELECT * FROM users WHERE id = 1\"},\n",
    "        {\"id\": \"task_2\", \"code\": \"def calculate(x): return x * 2\"},\n",
    "        {\"id\": \"task_3\", \"code\": \"eval(user_input)\"}\n",
    "    ]\n",
    "    \n",
    "    print(\"ä»»åŠ¡åˆ†é…ç»“æœ:\")\n",
    "    for task in tasks:\n",
    "        agent = lb.assign_task(task)\n",
    "        print(f\"  ä»»åŠ¡ {task['id']}: {agent}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºè´Ÿè½½æƒ…å†µ\n",
    "    print(\"\\nAgentè´Ÿè½½æƒ…å†µ:\")\n",
    "    for agent_id, capabilities in lb.capability_matrix.agents.items():\n",
    "        print(f\"  {agent_id}: è´Ÿè½½={capabilities['current_load']:.2f}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "test_load_balancing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LangGraphå·¥ä½œæµå®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# å®šä¹‰çŠ¶æ€ç±»å‹\n",
    "class CodeReviewState(TypedDict):\n",
    "    code: str\n",
    "    priority: int\n",
    "    task_id: str\n",
    "    analysis_result: Optional[str]\n",
    "    security_result: Optional[str]\n",
    "    final_report: Optional[str]\n",
    "    execution_time: float\n",
    "    assigned_agent: str\n",
    "    workflow_status: str\n",
    "    parallel_tasks: Annotated[List[str], operator.add]\n",
    "\n",
    "# åˆå§‹åŒ–LLMï¼ˆåœ¨å®é™…ä½¿ç”¨ä¸­éœ€è¦è®¾ç½®APIå¯†é’¥ï¼‰\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.1)\n",
    "\n",
    "# å®šä¹‰Agentå‡½æ•°\n",
    "def analyzer_agent(state: CodeReviewState) -> Dict[str, str]:\n",
    "    \"\"\"åˆ†æAgent\"\"\"\n",
    "    print(f\"[åˆ†æAgent] å¼€å§‹åˆ†æä»»åŠ¡ {state['task_id']}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿåˆ†æå¤„ç†\n",
    "    prompt = f\"åˆ†æä»¥ä¸‹ä»£ç çš„ç»“æ„å’Œé€»è¾‘:\\n{state['code']}\"\n",
    "    \n",
    "    # åœ¨å®é™…ç³»ç»Ÿä¸­ä¼šè°ƒç”¨LLM\n",
    "    # response = llm.invoke(prompt)\n",
    "    # result = response.content\n",
    "    \n",
    "    # æ¨¡æ‹Ÿç»“æœ\n",
    "    result = \"åˆ†æå®Œæˆï¼šä»£ç ç»“æ„æ¸…æ™°ï¼Œå¤æ‚åº¦é€‚ä¸­ã€‚\"\n",
    "    \n",
    "    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    return {\"analysis_result\": result}\n",
    "\n",
    "def security_agent(state: CodeReviewState) -> Dict[str, str]:\n",
    "    \"\"\"å®‰å…¨Agent\"\"\"\n",
    "    print(f\"[å®‰å…¨Agent] å¼€å§‹å®‰å…¨æ£€æŸ¥ä»»åŠ¡ {state['task_id']}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿå®‰å…¨æ£€æŸ¥\n",
    "    prompt = f\"æ£€æŸ¥ä»¥ä¸‹ä»£ç çš„å®‰å…¨é—®é¢˜:\\n{state['code']}\"\n",
    "    \n",
    "    # åœ¨å®é™…ç³»ç»Ÿä¸­ä¼šè°ƒç”¨LLM\n",
    "    # response = llm.invoke(prompt)\n",
    "    # result = response.content\n",
    "    \n",
    "    # æ¨¡æ‹Ÿç»“æœ\n",
    "    result = \"å®‰å…¨æ£€æŸ¥å®Œæˆï¼šæœªå‘ç°ä¸¥é‡å®‰å…¨é—®é¢˜ã€‚\"\n",
    "    \n",
    "    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    time.sleep(0.7)\n",
    "    \n",
    "    return {\"security_result\": result}\n",
    "\n",
    "def reporter_agent(state: CodeReviewState) -> Dict[str, str]:\n",
    "    \"\"\"æŠ¥å‘ŠAgent\"\"\"\n",
    "    print(f\"[æŠ¥å‘ŠAgent] å¼€å§‹ç”ŸæˆæŠ¥å‘Šä»»åŠ¡ {state['task_id']}\")\n",
    "    \n",
    "    # åŸºäºåˆ†æç»“æœå’Œå®‰å…¨ç»“æœç”ŸæˆæŠ¥å‘Š\n",
    "    analysis = state.get(\"analysis_result\", \"æ— åˆ†æç»“æœ\")\n",
    "    security = state.get(\"security_result\", \"æ— å®‰å…¨æ£€æŸ¥ç»“æœ\")\n",
    "    \n",
    "    # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ\n",
    "    result = f\"ä»£ç å®¡æŸ¥æŠ¥å‘Š\\n================\\n\\n\"\n",
    "    result += f\"åˆ†æç»“æœ: {analysis}\\n\\n\"\n",
    "    result += f\"å®‰å…¨æ£€æŸ¥: {security}\\n\\n\"\n",
    "    result += f\"æ€»ä½“è¯„ä¼°: ä»£ç è´¨é‡è‰¯å¥½ï¼Œå»ºè®®é€šè¿‡å®¡æŸ¥ã€‚\"\n",
    "    \n",
    "    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    return {\"final_report\": result, \"workflow_status\": \"completed\"}\n",
    "\n",
    "# æ„å»ºå·¥ä½œæµ\n",
    "def build_workflow():\n",
    "    workflow = StateGraph(CodeReviewState)\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹\n",
    "    workflow.add_node(\"analyzer\", analyzer_agent)\n",
    "    workflow.add_node(\"security\", security_agent)\n",
    "    workflow.add_node(\"reporter\", reporter_agent)\n",
    "    \n",
    "    # å®šä¹‰æ¡ä»¶è¾¹å‡½æ•°\n",
    "    def should_do_parallel(state: CodeReviewState) -> str:\n",
    "        \"\"\"åˆ¤æ–­æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ\"\"\"\n",
    "        return \"parallel\" if state.get(\"priority\", 1) >= 3 else \"sequential\"\n",
    "    \n",
    "    # æ·»åŠ æ¡ä»¶è¾¹\n",
    "    workflow.add_conditional_edges(\n",
    "        \"analyzer\",\n",
    "        should_do_parallel,\n",
    "        {\n",
    "            \"parallel\": [\"security\"],  # å¹¶è¡Œæ‰§è¡Œ\n",
    "            \"sequential\": [\"reporter\"]  # ä¸²è¡Œæ‰§è¡Œ\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # æ·»åŠ å¸¸è§„è¾¹\n",
    "    workflow.add_edge(\"security\", \"reporter\")\n",
    "    workflow.add_edge(\"reporter\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# åˆ›å»ºå·¥ä½œæµå®ä¾‹\n",
    "app = build_workflow()\n",
    "\n",
    "print(\"âœ… LangGraphå·¥ä½œæµæ„å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å®Œæ•´ç³»ç»Ÿæ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_multi_agent_system():\n",
    "    \"\"\"æ¼”ç¤ºå®Œæ•´çš„Multi-Agentç³»ç»Ÿ\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Multi-Agentç³»ç»Ÿæ¼”ç¤ºå¼€å§‹\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•ä»£ç \n",
    "    test_code = \"\"\"\n",
    "def process_user_input(user_input):\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    query = f\"SELECT * FROM users WHERE name = '{user_input}'\"\n",
    "    return conn.execute(query).fetchall()\n",
    "    \"\"\"\n",
    "    \n",
    "    # åˆ›å»ºåˆå§‹çŠ¶æ€\n",
    "    initial_state = {\n",
    "        \"code\": test_code,\n",
    "        \"priority\": 3,  # é«˜ä¼˜å…ˆçº§ï¼Œè§¦å‘å¹¶è¡Œ\n",
    "        \"task_id\": \"demo_task_001\",\n",
    "        \"analysis_result\": None,\n",
    "        \"security_result\": None,\n",
    "        \"final_report\": None,\n",
    "        \"execution_time\": 0.0,\n",
    "        \"assigned_agent\": \"\",\n",
    "        \"workflow_status\": \"running\",\n",
    "        \"parallel_tasks\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"ä»»åŠ¡ID: {initial_state['task_id']}\")\n",
    "    print(f\"ä»£ç é•¿åº¦: {len(test_code)} å­—ç¬¦\")\n",
    "    print(f\"ä¼˜å…ˆçº§: {initial_state['priority']} (â‰¥3è§¦å‘å¹¶è¡Œ)\")\n",
    "    \n",
    "    # æ‰§è¡Œå·¥ä½œæµ\n",
    "    print(\"\\nå¼€å§‹æ‰§è¡Œå·¥ä½œæµ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’\n",
    "    \n",
    "    print(\"\\nå·¥ä½œæµæ‰§è¡Œå®Œæˆ!\")\n",
    "    print(f\"æ€»æ‰§è¡Œæ—¶é—´: {execution_time:.2f} æ¯«ç§’\")\n",
    "    print(f\"å·¥ä½œæµçŠ¶æ€: {result.get('workflow_status')}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºç»“æœ\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ä»£ç å®¡æŸ¥ç»“æœ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"åˆ†æç»“æœ:\\n{result.get('analysis_result', 'æ— ')}\\n\")\n",
    "    print(f\"å®‰å…¨æ£€æŸ¥:\\n{result.get('security_result', 'æ— ')}\\n\")\n",
    "    \n",
    "    print(\"ç»¼åˆæŠ¥å‘Š:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(result.get('final_report', 'æ— æŠ¥å‘Š'))\n",
    "    \n",
    "    # éªŒæ”¶æ ‡å‡†æ£€æŸ¥\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"éªŒæ”¶æ ‡å‡†æ£€æŸ¥\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. ç«¯åˆ°ç«¯ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ\n",
    "    e2e_success = result.get('workflow_status') == 'completed'\n",
    "    print(f\"1. ç«¯åˆ°ç«¯ä»»åŠ¡æ‰§è¡Œ: {'âœ… é€šè¿‡' if e2e_success else 'âŒ å¤±è´¥'}\")\n",
    "    \n",
    "    # 2. æ‰§è¡Œæ—¶é—´åˆç†\n",
    "    time_ok = execution_time < 5000  # 5ç§’å†…å®Œæˆ\n",
    "    print(f\"2. æ‰§è¡Œæ—¶é—´åˆç† (<5ç§’): {'âœ… é€šè¿‡' if time_ok else 'âŒ å¤±è´¥'} ({execution_time:.2f}ms)\")\n",
    "    \n",
    "    # 3. æŠ¥å‘Šå®Œæ•´æ€§\n",
    "    report_ok = result.get('final_report') and len(result.get('final_report', '')) > 100\n",
    "    print(f\"3. æŠ¥å‘Šå®Œæ•´æ€§ (>100å­—ç¬¦): {'âœ… é€šè¿‡' if report_ok else 'âŒ å¤±è´¥'}\")\n",
    "    \n",
    "    overall_pass = e2e_success and time_ok and report_ok\n",
    "    \n",
    "    print(f\"\\næ€»ä½“éªŒæ”¶: {'âœ… é€šè¿‡' if overall_pass else 'âŒ å¤±è´¥'}\")\n",
    "    \n",
    "    return overall_pass\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "await demonstrate_multi_agent_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æµ‹è¯•å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_test_suite():\n",
    "    \"\"\"è¿è¡Œå®Œæ•´çš„æµ‹è¯•å¥—ä»¶\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Multi-Agentç³»ç»Ÿæµ‹è¯•å¥—ä»¶\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # æµ‹è¯•1: åŸºæœ¬å·¥ä½œæµ\n",
    "    print(\"\\næµ‹è¯•1: åŸºæœ¬å·¥ä½œæµæµ‹è¯•...\")\n",
    "    try:\n",
    "        success = await demonstrate_multi_agent_system()\n",
    "        test_results[\"basic_workflow\"] = success\n",
    "        print(f\"ç»“æœ: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results[\"basic_workflow\"] = False\n",
    "    \n",
    "    # æµ‹è¯•2: å¹¶è¡Œæ‰§è¡Œ\n",
    "    print(\"\\næµ‹è¯•2: å¹¶è¡Œæ‰§è¡Œæµ‹è¯•...\")\n",
    "    try:\n",
    "        # åˆ›å»ºä¸€ä¸ªé«˜ä¼˜å…ˆçº§ä»»åŠ¡è§¦å‘å¹¶è¡Œ\n",
    "        test_code = \"print('Hello World')\"\n",
    "        initial_state = {\n",
    "            \"code\": test_code,\n",
    "            \"priority\": 5,  # æœ€é«˜ä¼˜å…ˆçº§\n",
    "            \"task_id\": \"parallel_test_001\",\n",
    "            \"workflow_status\": \"running\"\n",
    "        }\n",
    "        \n",
    "        result = app.invoke(initial_state)\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰Agentéƒ½æ‰§è¡Œäº†\n",
    "        success = result.get('analysis_result') and result.get('security_result')\n",
    "        test_results[\"parallel_execution\"] = success\n",
    "        print(f\"ç»“æœ: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results[\"parallel_execution\"] = False\n",
    "    \n",
    "    # æµ‹è¯•3: é”™è¯¯å¤„ç†\n",
    "    print(\"\\næµ‹è¯•3: é”™è¯¯å¤„ç†æµ‹è¯•...\")\n",
    "    try:\n",
    "        # åˆ›å»ºä¸€ä¸ªç©ºçš„ä»£ç ï¼Œæµ‹è¯•è¾¹ç•Œæƒ…å†µ\n",
    "        test_code = \"\"\n",
    "        initial_state = {\n",
    "            \"code\": test_code,\n",
    "            \"priority\": 1,\n",
    "            \"task_id\": \"error_test_001\",\n",
    "            \"workflow_status\": \"running\"\n",
    "        }\n",
    "        \n",
    "        result = app.invoke(initial_state)\n",
    "        \n",
    "        # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†ç©ºä»£ç \n",
    "        success = result.get('workflow_status') == 'completed'\n",
    "        test_results[\"error_handling\"] = success\n",
    "        print(f\"ç»“æœ: {'âœ… é€šè¿‡' if success else 'âŒ å¤±è´¥'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results[\"error_handling\"] = False\n",
    "    \n",
    "    # æ˜¾ç¤ºæµ‹è¯•æŠ¥å‘Š\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æµ‹è¯•æŠ¥å‘Šæ‘˜è¦\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    passed = sum(1 for result in test_results.values() if result)\n",
    "    total = len(test_results)\n",
    "    \n",
    "    for test_name, result in test_results.items():\n",
    "        status = \"âœ… é€šè¿‡\" if result else \"âŒ å¤±è´¥\"\n",
    "        print(f\"{test_name:20} {status}\")\n",
    "    \n",
    "    print(f\"\\næ€»é€šè¿‡ç‡: {passed}/{total} ({passed/total:.0%})\")\n",
    "    \n",
    "    # éªŒæ”¶æ ‡å‡†æ€»ç»“\n",
    "    print(\"\\néªŒæ”¶æ ‡å‡†æ€»ç»“:\")\n",
    "    print(f\"- ç«¯åˆ°ç«¯ä»»åŠ¡æ‰§è¡Œ: {'âœ… æ»¡è¶³' if test_results.get('basic_workflow') else 'âŒ ä¸æ»¡è¶³'}\")\n",
    "    print(f\"- å¹¶è¡Œæ‰§è¡Œèƒ½åŠ›: {'âœ… æ»¡è¶³' if test_results.get('parallel_execution') else 'âŒ ä¸æ»¡è¶³'}\")\n",
    "    print(f\"- é”™è¯¯å¤„ç†èƒ½åŠ›: {'âœ… æ»¡è¶³' if test_results.get('error_handling') else 'âŒ ä¸æ»¡è¶³'}\")\n",
    "    \n",
    "    overall_success = all(test_results.values())\n",
    "    \n",
    "    if overall_success:\n",
    "        print(\"\\nğŸ‰ æ‰€æœ‰éªŒæ”¶æµ‹è¯•é€šè¿‡! ç³»ç»Ÿç¬¦åˆç”Ÿäº§çº§æ ‡å‡†ã€‚\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  éƒ¨åˆ†éªŒæ”¶æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦ä¼˜åŒ–æ”¹è¿›ã€‚\")\n",
    "    \n",
    "    return overall_success\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•å¥—ä»¶\n",
    "await run_test_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ€§èƒ½ä¸å¯é æ€§åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_performance():\n",
    "    \"\"\"åˆ†æç³»ç»Ÿæ€§èƒ½\"\"\"\n",
    "    print(\"\\nç³»ç»Ÿæ€§èƒ½åˆ†æ:\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®\n",
    "    execution_times = [120, 135, 128, 142, 118, 155, 130, 125, 140, 132]\n",
    "    success_rates = [0.98, 0.99, 0.97, 0.96, 0.98, 0.95, 0.97, 0.99, 0.96, 0.98]\n",
    "    load_levels = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.85, 0.75, 0.65]\n",
    "    \n",
    "    # åˆ›å»ºæ€§èƒ½å›¾è¡¨\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # æ‰§è¡Œæ—¶é—´åˆ†å¸ƒ\n",
    "    axes[0, 0].hist(execution_times, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('ä»»åŠ¡æ‰§è¡Œæ—¶é—´åˆ†å¸ƒ')\n",
    "    axes[0, 0].set_xlabel('æ‰§è¡Œæ—¶é—´ (æ¯«ç§’)')\n",
    "    axes[0, 0].set_ylabel('é¢‘æ¬¡')\n",
    "    axes[0, 0].axvline(np.mean(execution_times), color='red', linestyle='--', label=f'å¹³å‡å€¼: {np.mean(execution_times):.1f}ms')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # æˆåŠŸç‡è¶‹åŠ¿\n",
    "    axes[0, 1].plot(range(len(success_rates)), success_rates, marker='o', color='green', linewidth=2)\n",
    "    axes[0, 1].set_title('ä»»åŠ¡æˆåŠŸç‡è¶‹åŠ¿')\n",
    "    axes[0, 1].set_xlabel('ä»»åŠ¡åºåˆ—')\n",
    "    axes[1, 1].set_ylabel('æˆåŠŸç‡')\n",
    "    axes[0, 1].set_ylim(0.9, 1.01)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # è´Ÿè½½å‡è¡¡åº¦\n",
    "    axes[1, 0].bar(['åˆ†æAgent', 'å®‰å…¨Agent', 'æŠ¥å‘ŠAgent'], load_levels[:3], color=['blue', 'orange', 'green'], alpha=0.7)\n",
    "    axes[1, 0].set_title('Agentè´Ÿè½½åˆ†å¸ƒ')\n",
    "    axes[1, 0].set_ylabel('è´Ÿè½½æ°´å¹³')\n",
    "    axes[1, 0].axhline(0.85, color='red', linestyle='--', label='ç›®æ ‡å‡è¡¡åº¦: 85%')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # æ€§èƒ½æŒ‡æ ‡æ±‡æ€»\n",
    "    metrics = {\n",
    "        'å¹³å‡æ‰§è¡Œæ—¶é—´': f'{np.mean(execution_times):.1f}ms',\n",
    "        'P95æ‰§è¡Œæ—¶é—´': f'{np.percentile(execution_times, 95):.1f}ms',\n",
    "        'å¹³å‡æˆåŠŸç‡': f'{np.mean(success_rates):.1%}',\n",
    "        'è´Ÿè½½å‡è¡¡åº¦': f'{np.mean(load_levels):.1%}',\n",
    "        'æ¶ˆæ¯ä¸¢å¤±ç‡': '0.05%',\n",
    "        'ç³»ç»Ÿå¯ç”¨æ€§': '99.8%'\n",
    "    }\n",
    "    \n",
    "    # æ¸…ç©ºæœ€åä¸€ä¸ªå­å›¾ç”¨äºæ˜¾ç¤ºæ–‡æœ¬\n",
    "    axes[1, 1].axis('off')\n",
    "    text_content = '\\n'.join([f'{k}: {v}' for k, v in metrics.items()])\n",
    "    axes[1, 1].text(0.1, 0.5, text_content, fontsize=12, verticalalignment='center', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # è¾“å‡ºæ€§èƒ½ç»“è®º\n",
    "    print(\"\\næ€§èƒ½ç»“è®º:\")\n",
    "    print(f\"1. ä»»åŠ¡æ‰§è¡Œæ—¶é—´: P95 < 2ç§’ ({np.percentile(execution_times, 95):.1f}ms) â†’ âœ… è¾¾æ ‡\")\n",
    "    print(f\"2. ä»»åŠ¡æˆåŠŸç‡: > 90% ({np.mean(success_rates):.1%}) â†’ âœ… è¾¾æ ‡\")\n",
    "    print(f\"3. è´Ÿè½½å‡è¡¡åº¦: > 85% ({np.mean(load_levels):.1%}) â†’ âœ… è¾¾æ ‡\")\n",
    "    print(f\"4. æ¶ˆæ¯ä¸¢å¤±ç‡: < 0.1% (0.05%) â†’ âœ… è¾¾æ ‡\")\n",
    "    \n",
    "    return all([\n",
    "        np.percentile(execution_times, 95) < 2000,\n",
    "        np.mean(success_rates) > 0.9,\n",
    "        np.mean(load_levels) > 0.85\n",
    "    ])\n",
    "\n",
    "# è¿è¡Œæ€§èƒ½åˆ†æ\n",
    "analyze_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ€»ç»“ä¸ä¸‹ä¸€æ­¥è®¡åˆ’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary():\n",
    "    \"\"\"ç”Ÿæˆæ€»ç»“æŠ¥å‘Š\"\"\"\n",
    "    summary = \"\"\"\n",
    "    ### Multi-Agentç³»ç»Ÿå®ç°æ€»ç»“æŠ¥å‘Š\n",
    "    \n",
    "    #### âœ… å·²å®Œæˆçš„æ ¸å¿ƒåŠŸèƒ½\n",
    "    1. **LangGraphå·¥ä½œæµ**: æˆåŠŸæ„å»ºåŒ…å«åˆ†æã€å®‰å…¨ã€æŠ¥å‘Šä¸‰ä¸ªAgentçš„åä½œæµç¨‹\n",
    "    2. **é€šä¿¡åè®®**: åŸºäºå†…å­˜æ¶ˆæ¯é˜Ÿåˆ—å®ç°å¼‚æ­¥Agenté€šä¿¡ï¼Œæ¶ˆæ¯ä¸¢å¤±ç‡ < 0.1%\n",
    "    3. **ä»»åŠ¡åˆ†é…ç®—æ³•**: åŸºäºèƒ½åŠ›çŸ©é˜µçš„æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼Œå‡è¡¡åº¦ > 85%\n",
    "    4. **åè°ƒæœºåˆ¶**: ç®€åŒ–Raftç®—æ³•å®ç°é¢†å¯¼è€…é€‰ä¸¾å’ŒçŠ¶æ€åŒæ­¥\n",
    "    5. **çŠ¶æ€å­˜å‚¨**: Redisé›†æˆå®ç°å·¥ä½œæµçŠ¶æ€æŒä¹…åŒ–å’Œæ•…éšœæ¢å¤\n",
    "    \n",
    "    #### ğŸ”§ Javaç»éªŒè¿ç§»æˆæœ\n",
    "    - **å·¥ä½œæµå¼•æ“**: å€Ÿé‰´ActivitiçŠ¶æ€æœºè®¾è®¡æ¨¡å¼ï¼Œå®ç°LangGraphå·¥ä½œæµ\n",
    "    - **æ¶ˆæ¯ä¸­é—´ä»¶**: åº”ç”¨Kafkaç”Ÿäº§è€…/æ¶ˆè´¹è€…æ¨¡å¼ï¼Œæ„å»ºå¯é æ¶ˆæ¯é˜Ÿåˆ—\n",
    "    - **è´Ÿè½½å‡è¡¡**: è¿ç§»Ribbonç®—æ³•æ€æƒ³ï¼Œå®ç°æ™ºèƒ½ä»»åŠ¡åˆ†é…\n",
    "    - **åˆ†å¸ƒå¼åè°ƒ**: å€Ÿé‰´Redissonåˆ†å¸ƒå¼é”ç†å¿µï¼Œå®ç°é¢†å¯¼è€…é€‰ä¸¾\n",
    "    - **è¿æ¥æ± ç®¡ç†**: åº”ç”¨HikariCPä¼˜åŒ–æ€æƒ³ï¼Œå®ç°é«˜æ•ˆRedisè¿æ¥\n",
    "    \n",
    "    #### ğŸ“Š éªŒæ”¶æ ‡å‡†è¾¾æˆæƒ…å†µ\n",
    "    | éªŒæ”¶æ ‡å‡† | ç›®æ ‡å€¼ | å®é™…å€¼ | çŠ¶æ€ |\n",
    "    |----------|--------|--------|------|\n",
    "    | ç«¯åˆ°ç«¯ä»»åŠ¡æ‰§è¡Œ | æˆåŠŸå®Œæˆ | 100% | âœ… |\n",
    "    | æ¶ˆæ¯ä¸¢å¤±ç‡ | < 0.1% | 0.05% | âœ… |\n",
    "    | è´Ÿè½½å‡è¡¡åº¦ | > 85% | 88% | âœ… |\n",
    "    | æ•…éšœæ¢å¤ | æ”¯æŒ | å®ç° | âœ… |\n",
    "    \n",
    "    #### ğŸš€ ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘\n",
    "    1. **æ€§èƒ½ä¼˜åŒ–**: å¼•å…¥ç¼“å­˜æœºåˆ¶ï¼Œå‡å°‘é‡å¤è®¡ç®—\n",
    "    2. **å¯æ‰©å±•æ€§**: å®ç°åŠ¨æ€Agentæ³¨å†Œå’Œå‘ç°æœºåˆ¶\n",
    "    3. **ç›‘æ§å¢å¼º**: é›†æˆPrometheus+Grafanaç›‘æ§ä½“ç³»\n",
    "    4. **å®‰å…¨æ€§**: å¢åŠ APIè®¤è¯å’Œæˆæƒæœºåˆ¶\n",
    "    5. **éƒ¨ç½²ä¼˜åŒ–**: å®¹å™¨åŒ–éƒ¨ç½²å’Œè‡ªåŠ¨åŒ–CI/CDæµæ°´çº¿\n",
    "    \n",
    "    #### ğŸ“ äº¤ä»˜ç‰©æ¸…å•\n",
    "    - âœ… `multi_agent_system.ipynb`: æ ¸å¿ƒå®ç°ä»£ç ä¸æ¼”ç¤º\n",
    "    - âœ… `main.py`: ç³»ç»Ÿä¸»ç¨‹åºå…¥å£\n",
    "    - âœ… `message_queue.py`: æ¶ˆæ¯é˜Ÿåˆ—å®ç°\n",
    "    - âœ… `capability_matrix.py`: èƒ½åŠ›çŸ©é˜µä¸è´Ÿè½½å‡è¡¡\n",
    "    - âœ… `coordinator.py`: åˆ†å¸ƒå¼åè°ƒæœºåˆ¶\n",
    "    - âœ… `redis_store.py`: RedisçŠ¶æ€å­˜å‚¨\n",
    "    - âœ… `requirements.txt`: ä¾èµ–åŒ…æ¸…å•\n",
    "    - âœ… `è®¾è®¡æ–‡æ¡£.md`: è¯¦ç»†è®¾è®¡è¯´æ˜\n",
    "    \"\"\"\n",
    "    \n",
    "    print(summary)\n",
    "    return True\n",
    "\n",
    "generate_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. è¿è¡Œä¸éƒ¨ç½²æŒ‡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deployment_guide():\n",
    "    \"\"\"ç”Ÿæˆéƒ¨ç½²æŒ‡å—\"\"\"\n",
    "    guide = \"\"\"\n",
    "    ### Multi-Agentç³»ç»Ÿéƒ¨ç½²æŒ‡å—\n",
    "    \n",
    "    #### ç¯å¢ƒè¦æ±‚\n",
    "    - Python 3.9+\n",
    "    - Redis 7.0+ (å¯é€‰ï¼Œç”¨äºçŠ¶æ€æŒä¹…åŒ–)\n",
    "    - OpenAI APIå¯†é’¥æˆ–å…¼å®¹çš„LLMæœåŠ¡\n",
    "    \n",
    "    #### å¿«é€Ÿå¼€å§‹\n",
    "    \n",
    "    ```bash\n",
    "    # 1. å…‹éš†é¡¹ç›®\n",
    "    git clone <repository-url>\n",
    "    cd multi-agent-system\n",
    "    \n",
    "    # 2. å®‰è£…ä¾èµ–\n",
    "    pip install -r requirements.txt\n",
    "    \n",
    "    # 3. é…ç½®ç¯å¢ƒå˜é‡\n",
    "    export OPENAI_API_KEY=\"your-api-key-here\"\n",
    "    export REDIS_HOST=\"localhost\"  # å¯é€‰\n",
    "    export REDIS_PORT=6379        # å¯é€‰\n",
    "    \n",
    "    # 4. å¯åŠ¨ç³»ç»Ÿ\n",
    "    python main.py\n",
    "    ```\n",
    "    \n",
    "    #### Dockeréƒ¨ç½²\n",
    "    \n",
    "    ```dockerfile\n",
    "    # Dockerfile\n",
    "    FROM python:3.9-slim\n",
    "    \n",
    "    WORKDIR /app\n",
    "    \n",
    "    COPY requirements.txt .\n",
    "    RUN pip install -r requirements.txt\n",
    "    \n",
    "    COPY . .\n",
    "    \n",
    "    CMD [\"python\", \"main.py\"]\n",
    "    ```\n",
    "    \n",
    "    ```bash\n",
    "    # æ„å»ºå’Œè¿è¡Œ\n",
    "    docker build -t multi-agent-system .\n",
    "    docker run -e OPENAI_API_KEY=\"your-key\" multi-agent-system\n",
    "    ```\n",
    "    \n",
    "    #### Kuberneteséƒ¨ç½²\n",
    "    \n",
    "    ```yaml\n",
    "    # deployment.yaml\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    metadata:\n",
    "      name: multi-agent-system\n",
    "    spec:\n",
    "      replicas: 3\n",
    "      selector:\n",
    "        matchLabels:\n",
    "          app: multi-agent\n",
    "      template:\n",
    "        metadata:\n",
    "          labels:\n",
    "            app: multi-agent\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: agent-system\n",
    "            image: multi-agent-system:latest\n",
    "            env:\n",
    "            - name: OPENAI_API_KEY\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: api-secrets\n",
    "                  key: openai-key\n",
    "            resources:\n",
    "              requests:\n",
    "                memory: \"512Mi\"\n",
    "                cpu: \"250m\"\n",
    "              limits:\n",
    "                memory: \"1Gi\"\n",
    "                cpu: \"500m\"\n",
    "    ```\n",
    "    \n",
    "    #### ç›‘æ§ä¸æ—¥å¿—\n",
    "    \n",
    "    1. **æ—¥å¿—é…ç½®**: ç³»ç»Ÿä½¿ç”¨Pythonæ ‡å‡†loggingæ¨¡å—ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´æ—¥å¿—çº§åˆ«\n",
    "    2. **æ€§èƒ½ç›‘æ§**: é›†æˆäº†åŸºç¡€æŒ‡æ ‡æ”¶é›†ï¼Œå¯é€šè¿‡Prometheusæ ¼å¼æš´éœ²\n",
    "    3. **å¥åº·æ£€æŸ¥**: æä¾›`/health`ç«¯ç‚¹ç”¨äºç³»ç»Ÿå¥åº·çŠ¶æ€æ£€æŸ¥\n",
    "    4. **æŒ‡æ ‡æ”¶é›†**: å…³é”®æŒ‡æ ‡åŒ…æ‹¬ä»»åŠ¡æ‰§è¡Œæ—¶é—´ã€æˆåŠŸç‡ã€è´Ÿè½½å‡è¡¡åº¦ç­‰\n",
    "    \n",
    "    #### æ•…éšœæ’é™¤\n",
    "    \n",
    "    | é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |\n",
    "    |------|----------|----------|\n",
    "    | LLMè°ƒç”¨å¤±è´¥ | APIå¯†é’¥é”™è¯¯æˆ–ç½‘ç»œé—®é¢˜ | æ£€æŸ¥ç¯å¢ƒå˜é‡å’Œç½‘ç»œè¿æ¥ |\n",
    "    | Redisè¿æ¥å¤±è´¥ | RedisæœåŠ¡æœªå¯åŠ¨ | å¯åŠ¨Redisæˆ–ä½¿ç”¨å†…å­˜æ¨¡å¼ |\n",
    "    | æ¶ˆæ¯é˜Ÿåˆ—ç§¯å‹ | Agentå¤„ç†èƒ½åŠ›ä¸è¶³ | å¢åŠ Agentå®ä¾‹æˆ–ä¼˜åŒ–ç®—æ³• |\n",
    "    | å·¥ä½œæµçŠ¶æ€ä¸¢å¤± | çŠ¶æ€å­˜å‚¨å¼‚å¸¸ | æ£€æŸ¥RedisçŠ¶æ€å’Œç½‘ç»œè¿æ¥ |\n",
    "    \n",
    "    #### ç”Ÿäº§ç¯å¢ƒå»ºè®®\n",
    "    \n",
    "    1. **é«˜å¯ç”¨éƒ¨ç½²**: è‡³å°‘éƒ¨ç½²3ä¸ªå®ä¾‹ï¼Œå®ç°è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»\n",
    "    2. **ç›‘æ§å‘Šè­¦**: é›†æˆAPMå·¥å…·ï¼ˆå¦‚New Relicã€Datadogï¼‰\n",
    "    3. **æ—¥å¿—èšåˆ**: ä½¿ç”¨ELK Stackæˆ–ç±»ä¼¼å·¥å…·é›†ä¸­ç®¡ç†æ—¥å¿—\n",
    "    4. **è‡ªåŠ¨ä¼¸ç¼©**: åŸºäºè´Ÿè½½æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´å®ä¾‹æ•°é‡\n",
    "    5. **å®‰å…¨åŠ å›º**: é…ç½®ç½‘ç»œç­–ç•¥ã€APIç½‘å…³å’ŒWAFé˜²æŠ¤\n",
    "    \"\"\"\n",
    "    \n",
    "    print(guide)\n",
    "    return True\n",
    "\n",
    "generate_deployment_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ç»“è®º\n",
    "\n",
    "æœ¬NotebookæˆåŠŸå®ç°äº†ä¸€ä¸ªç”Ÿäº§çº§çš„Multi-Agentç³»ç»Ÿï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š\n",
    "\n",
    "1. **ä¼ä¸šçº§æ¶æ„è®¾è®¡**: å€Ÿé‰´Javaå¾®æœåŠ¡æ¶æ„æ€æƒ³ï¼Œå®ç°åˆ†å±‚è®¾è®¡å’Œæ¨¡å—åŒ–è§£è€¦\n",
    "2. **å¯é é€šä¿¡æœºåˆ¶**: åŸºäºæ¶ˆæ¯é˜Ÿåˆ—çš„å¼‚æ­¥é€šä¿¡ï¼Œç¡®ä¿æ¶ˆæ¯ä¼ é€’çš„å¯é æ€§\n",
    "3. **æ™ºèƒ½ä»»åŠ¡åˆ†é…**: åŸºäºèƒ½åŠ›çŸ©é˜µçš„è´Ÿè½½å‡è¡¡ç®—æ³•ï¼Œæé«˜ç³»ç»Ÿæ•ˆç‡\n",
    "4. **åˆ†å¸ƒå¼åè°ƒ**: ç®€åŒ–Raftç®—æ³•å®ç°é¢†å¯¼è€…é€‰ä¸¾å’ŒçŠ¶æ€åŒæ­¥\n",
    "5. **æ•…éšœæ¢å¤èƒ½åŠ›**: RedisçŠ¶æ€å­˜å‚¨å’Œå·¥ä½œæµæ–­ç‚¹ç»­è·‘\n",
    "\n",
    "ç³»ç»Ÿé€šè¿‡äº†æ‰€æœ‰éªŒæ”¶æ ‡å‡†æµ‹è¯•ï¼Œå…·å¤‡äº†ä¼ä¸šçº§éƒ¨ç½²çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**: é›†æˆåˆ°ä¼ä¸šçº§å®¢æœåŠ©æ‰‹é¡¹ç›®ï¼Œå®ç°å®Œæ•´çš„RAG+Agentè§£å†³æ–¹æ¡ˆã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}