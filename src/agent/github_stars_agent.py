#!/usr/bin/env python3
"""
GitHub Stars Agent - åŸºäº LangGraph çš„æ™ºèƒ½ç´¢å¼•ç”Ÿæˆå™¨

ä½¿ç”¨ LLM æ™ºèƒ½åˆ†æå’Œåˆ†ç±» GitHub starred ä»“åº“ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç´¢å¼•æ–‡æ¡£ã€‚

åŠŸèƒ½ï¼š
- è‡ªåŠ¨è·å–ï¼šç›´æ¥ä» GitHub API è·å– starred ä»“åº“æ•°æ®
- æ™ºèƒ½åˆ†ç±»ï¼šä½¿ç”¨ LLM åˆ†æä»“åº“çš„æŠ€æœ¯æ ˆã€ç”¨é€”ã€é¢†åŸŸ
- è‡ªåŠ¨æ€»ç»“ï¼šä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆæè¿°æ€§è¯´æ˜
- æ™ºèƒ½æ’åºï¼šæ ¹æ®ç›¸å…³æ€§å’Œé‡è¦æ€§æ’åº
- æ¨èç³»ç»Ÿï¼šè¯†åˆ«å…³é”®é¡¹ç›®å’Œå­¦ä¹ è·¯å¾„
"""

import json
import os
import sys
from datetime import datetime
from typing import Annotated, Dict, List, Optional, TypedDict

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from src.util import get_qwen_model

try:
    import requests
except ImportError:
    print("é”™è¯¯: éœ€è¦å®‰è£… requests åº“")
    print("è¯·è¿è¡Œ: pip install requests")
    sys.exit(1)


# ============================================================================
# GitHub API æ•°æ®è·å–
# ============================================================================


class GitHubStarsFetcher:
    """GitHub Stars ä¿¡æ¯çˆ¬å–å™¨"""

    def __init__(self, token: str):
        """
        åˆå§‹åŒ–çˆ¬å–å™¨

        Args:
            token: GitHub Personal Access Token
        """
        self.token = token
        self.base_url = "https://api.github.com"
        self.headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json",
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def get_authenticated_user(self) -> Dict:
        """è·å–å½“å‰è®¤è¯ç”¨æˆ·ä¿¡æ¯"""
        url = f"{self.base_url}/user"
        response = self.session.get(url)
        response.raise_for_status()
        return response.json()

    def fetch_starred_repos(
            self, username: Optional[str] = None, per_page: int = 100
    ) -> List[Dict]:
        """
        è·å–ç”¨æˆ·çš„æ‰€æœ‰ starred ä»“åº“

        Args:
            username: GitHub ç”¨æˆ·åï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™è·å–è®¤è¯ç”¨æˆ·ï¼‰
            per_page: æ¯é¡µè¿”å›çš„ä»“åº“æ•°é‡ï¼ˆæœ€å¤§ 100ï¼‰

        Returns:
            åŒ…å«æ‰€æœ‰ starred ä»“åº“ä¿¡æ¯çš„åˆ—è¡¨
        """
        if username:
            url = f"{self.base_url}/users/{username}/starred"
        else:
            url = f"{self.base_url}/user/starred"

        all_repos = []
        page = 1

        print(f"ğŸ”„ æ­£åœ¨è·å– starred ä»“åº“ä¿¡æ¯...")

        while True:
            params = {"per_page": per_page, "page": page}
            response = self.session.get(url, params=params)
            response.raise_for_status()

            repos = response.json()
            if not repos:
                break

            all_repos.extend(repos)
            print(f"  å·²è·å– {len(all_repos)} ä¸ªä»“åº“...", end="\r")

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
            link_header = response.headers.get("Link", "")
            if "rel=\"next\"" not in link_header:
                break

            page += 1

        print(f"\nâœ“ å…±è·å–åˆ° {len(all_repos)} ä¸ª starred ä»“åº“")
        return all_repos

    def extract_repo_info(self, repo: Dict) -> Dict:
        """
        ä»ä»“åº“æ•°æ®ä¸­æå–éœ€è¦çš„ä¿¡æ¯

        Args:
            repo: GitHub API è¿”å›çš„ä»“åº“æ•°æ®

        Returns:
            æå–åçš„ä»“åº“ä¿¡æ¯
        """
        return {
            "name": repo["name"],
            "full_name": repo["full_name"],
            "owner": repo["owner"]["login"],
            "description": repo["description"] or "æ— æè¿°",
            "url": repo["html_url"],
            "homepage": repo["homepage"],
            "stars": repo["stargazers_count"],
            "forks": repo["forks_count"],
            "language": repo["language"] or "-",
            "topics": repo.get("topics", []),
            "license": repo["license"]["name"] if repo["license"] else None,
            "created_at": repo["created_at"],
            "updated_at": repo["updated_at"],
            "pushed_at": repo["pushed_at"],
            "is_fork": repo["fork"],
            "is_archived": repo["archived"],
            "open_issues": repo["open_issues_count"],
        }


# ============================================================================
# åˆ†ç±»èŠ‚ç‚¹ç±»ï¼ˆé¢å‘å¯¹è±¡è®¾è®¡ï¼‰
# ============================================================================


class CategoryNode:
    """åˆ†ç±»èŠ‚ç‚¹ç±» - æ”¯æŒä»»æ„å±‚çº§çš„æ ‘å½¢ç»“æ„"""

    def __init__(self, name: str, description: str = "", repos: List[int] = None):
        """
        åˆå§‹åŒ–åˆ†ç±»èŠ‚ç‚¹
        
        Args:
            name: åˆ†ç±»åç§°
            description: åˆ†ç±»æè¿°
            repos: ä»“åº“ç´¢å¼•åˆ—è¡¨ï¼ˆåªåœ¨å¶å­èŠ‚ç‚¹æœ‰å€¼ï¼‰
        """
        self.name = name
        self.description = description
        self.repos = repos or []
        self.children: List['CategoryNode'] = []

    def add_child(self, child: 'CategoryNode') -> 'CategoryNode':
        """æ·»åŠ å­èŠ‚ç‚¹"""
        self.children.append(child)
        return child

    def is_leaf(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹"""
        return len(self.children) == 0

    def get_all_repos(self) -> List[int]:
        """é€’å½’è·å–æœ¬èŠ‚ç‚¹åŠæ‰€æœ‰å­èŠ‚ç‚¹çš„ä»“åº“"""
        all_repos = list(self.repos)
        for child in self.children:
            all_repos.extend(child.get_all_repos())
        return all_repos

    def get_path(self, parent_path: List[str] = None) -> List[str]:
        """è·å–ä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹çš„è·¯å¾„"""
        if parent_path is None:
            parent_path = []
        return parent_path + [self.name]

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = {
            "name": self.name,
            "description": self.description,
        }
        if self.repos:
            result["repos"] = self.repos
        if self.children:
            result["children"] = [child.to_dict() for child in self.children]
        return result

    @classmethod
    def from_dict(cls, data: Dict) -> 'CategoryNode':
        """ä»å­—å…¸åˆ›å»ºèŠ‚ç‚¹"""
        node = cls(
            name=data.get("name", ""),
            description=data.get("description", ""),
            repos=data.get("repos", [])
        )
        for child_data in data.get("children", []):
            node.add_child(cls.from_dict(child_data))
        return node

    def traverse(self, callback, depth: int = 0, parent_path: str = ""):
        """é€’å½’éå†æ ‘"""
        full_path = f"{parent_path} / {self.name}" if parent_path else self.name
        callback(self, depth, full_path)

        for child in self.children:
            child.traverse(callback, depth + 1, full_path)

    def __repr__(self):
        return f"CategoryNode(name={self.name}, repos={len(self.repos)}, children={len(self.children)})"


# ============================================================================
# State å®šä¹‰
# ============================================================================


class AgentState(TypedDict):
    """Agent çŠ¶æ€"""
    messages: Annotated[List, add_messages]
    github_token: str  # GitHub Token
    username: Optional[str]  # GitHub ç”¨æˆ·å
    min_stars: int  # æœ€å° stars è¿‡æ»¤
    repositories: List[Dict]  # åŸå§‹ä»“åº“æ•°æ®
    categories: Dict[str, List[Dict]]  # åˆ†ç±»åçš„ä»“åº“
    category_descriptions: Dict[str, str]  # åˆ†ç±»æè¿°
    recommendations: List[str]  # æ¨èå’Œå­¦ä¹ è·¯å¾„
    markdown_output: str  # ç”Ÿæˆçš„ Markdown


# ============================================================================
# Agent èŠ‚ç‚¹
# ============================================================================


class GitHubStarsAgent:
    """GitHub Stars æ™ºèƒ½åˆ†æ Agent"""

    def __init__(self, llm=None):
        """
        åˆå§‹åŒ– Agent

        Args:
            llm: LLM å®ä¾‹ï¼Œé»˜è®¤ä½¿ç”¨ Qwen æ¨¡å‹
        """
        self.llm = llm or get_qwen_model()

    def fetch_github_stars(self, state: AgentState) -> AgentState:
        """
        ç¬¬ä¸€æ­¥ï¼šä» GitHub API è·å– starred ä»“åº“æ•°æ®
        """
        print("\n" + "=" * 70)
        print("ğŸ”„ æ­¥éª¤ 1/4: è·å– GitHub Stars æ•°æ®")
        print("=" * 70)

        github_token = state.get("github_token")
        username = state.get("username")
        min_stars = state.get("min_stars", 0)

        if not github_token:
            raise ValueError("æœªæä¾› GitHub Tokenï¼Œè¯·è®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡")

        try:
            # åˆå§‹åŒ– fetcher
            fetcher = GitHubStarsFetcher(github_token)

            # è·å–ç”¨æˆ·ä¿¡æ¯
            if not username:
                user = fetcher.get_authenticated_user()
                username = user["login"]
                print(f"âœ“ è®¤è¯æˆåŠŸ: {username}")

            # è·å– starred ä»“åº“
            raw_repos = fetcher.fetch_starred_repos(username)

            # æå–ä»“åº“ä¿¡æ¯
            repos = [fetcher.extract_repo_info(repo) for repo in raw_repos]

            # è¿‡æ»¤
            if min_stars > 0:
                repos = [r for r in repos if r["stars"] >= min_stars]
                print(f"âœ“ è¿‡æ»¤åå‰©ä½™ {len(repos)} ä¸ªä»“åº“ (>= {min_stars} stars)")

            state["repositories"] = repos
            state["messages"].append(
                AIMessage(content=f"âœ“ æˆåŠŸè·å– {len(repos)} ä¸ª GitHub starred ä»“åº“")
            )

        except requests.exceptions.HTTPError as e:
            error_msg = f"GitHub API è¯·æ±‚å¤±è´¥: {e}"
            if e.response.status_code == 401:
                error_msg += " (Token å¯èƒ½æ— æ•ˆæˆ–å·²è¿‡æœŸ)"
            state["messages"].append(AIMessage(content=f"âŒ {error_msg}"))
            raise

        except Exception as e:
            error_msg = f"è·å–æ•°æ®å¤±è´¥: {e}"
            state["messages"].append(AIMessage(content=f"âŒ {error_msg}"))
            raise

        return state

    def analyze_repositories(self, state: AgentState) -> AgentState:
        """
        åˆ†æä»“åº“å¹¶æ™ºèƒ½åˆ†ç±»

        ä½¿ç”¨ LLM åˆ†ææ¯ä¸ªä»“åº“çš„æŠ€æœ¯æ ˆã€ç”¨é€”å’Œé¢†åŸŸï¼Œè¿›è¡Œæ™ºèƒ½åˆ†ç±»
        """
        print("\n" + "=" * 70)
        print("ğŸ¤– æ­¥éª¤ 2/4: AI æ™ºèƒ½åˆ†æä¸åˆ†ç±»")
        print("=" * 70)

        repos = state["repositories"]
        print(f"ğŸ“Š å‡†å¤‡åˆ†æ {len(repos)} ä¸ªä»“åº“...")

        # å‡†å¤‡ä»“åº“æ‘˜è¦ï¼ˆé™åˆ¶æ•°é‡é¿å…è¶…å‡ºä¸Šä¸‹æ–‡ï¼‰
        max_repos = 105  # é™åˆ¶æœ€å¤§åˆ†ææ•°é‡ï¼ˆç¡®ä¿ AI å‡†ç¡®åˆ†ç±»ï¼‰
        analyze_repos = repos[:max_repos] if len(repos) > max_repos else repos

        if len(repos) > max_repos:
            print(f"âš ï¸  ä»“åº“æ•°é‡è¾ƒå¤šï¼Œå°†åˆ†æå‰ {max_repos} ä¸ªé«˜ star é¡¹ç›®")
            # æŒ‰ stars æ’åºï¼Œå–å‰ N ä¸ª
            analyze_repos = sorted(repos, key=lambda x: x["stars"], reverse=True)[:max_repos]

        repo_summaries = []
        for i, repo in enumerate(analyze_repos):
            summary = {
                "index": i,
                "name": repo["full_name"],
                "description": repo["description"][:100] if repo["description"] else "æ— æè¿°",  # é™åˆ¶æè¿°é•¿åº¦
                "language": repo["language"],
                "topics": repo.get("topics", [])[:3],  # åªå–å‰3ä¸ªtopic
                "stars": repo["stars"],
            }
            repo_summaries.append(summary)

        # åˆ›å»ºæ›´ç®€æ´çš„ä»“åº“åˆ—è¡¨ç”¨äºæç¤º
        repo_list_str = "\n".join([
            f"{i}. {repo['name']} - {repo['description'][:50]}... (â­{repo['stars']}, {repo['language']})"
            for i, repo in enumerate(repo_summaries)
        ])

        prompt = f"""åˆ†æä»¥ä¸‹ {len(repo_summaries)} ä¸ª GitHub ä»“åº“ï¼ŒæŒ‰æŠ€æœ¯é¢†åŸŸè¿›è¡Œå±‚çº§åˆ†ç±»ã€‚

ä»“åº“åˆ—è¡¨ï¼š
{repo_list_str}

è¦æ±‚ï¼š
1. ä½¿ç”¨çµæ´»çš„å¤šçº§åˆ†ç±»ç»“æ„ï¼ˆå¯ä»¥æ˜¯2-4çº§ï¼‰
2. æ¯ä¸ªä»“åº“åªèƒ½åˆ†é…åˆ°ä¸€ä¸ªæœ€ç»ˆåˆ†ç±»ï¼ˆå¶å­èŠ‚ç‚¹ï¼‰
3. æ‰€æœ‰ {len(repo_summaries)} ä¸ªä»“åº“éƒ½å¿…é¡»è¢«åˆ†é…
4. ä½¿ç”¨ä¸­æ–‡åˆ†ç±»åç§°

è¿”å›JSONæ ¼å¼ï¼ˆé€’å½’ç»“æ„ï¼Œæ”¯æŒä»»æ„å±‚çº§ï¼‰ï¼š
{{
  "categories": [
    {{
      "name": "AI/æœºå™¨å­¦ä¹ ",
      "description": "äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯",
      "children": [
        {{
          "name": "LLM",
          "description": "å¤§è¯­è¨€æ¨¡å‹",
          "children": [
            {{
              "name": "Agentæ¡†æ¶",
              "description": "æ™ºèƒ½ä»£ç†å¼€å‘æ¡†æ¶",
              "repos": [0, 3, 5]
            }},
            {{
              "name": "å‘é‡æ•°æ®åº“",
              "repos": [1, 2]
            }}
          ]
        }},
        {{
          "name": "æ·±åº¦å­¦ä¹ ",
          "repos": [4, 7, 9]
        }}
      ]
    }},
    {{
      "name": "Webå¼€å‘",
      "repos": [6, 8, 10]
    }}
  ]
}}

è¯´æ˜ï¼š
- name: èŠ‚ç‚¹åç§°ï¼ˆå¿…éœ€ï¼‰
- description: èŠ‚ç‚¹æè¿°ï¼ˆå¯é€‰ï¼‰
- children: å­èŠ‚ç‚¹æ•°ç»„ï¼ˆå¯åµŒå¥—ä»»æ„å±‚çº§ï¼‰
- repos: ä»“åº“ç´¢å¼•ï¼ˆåªåœ¨å¶å­èŠ‚ç‚¹ï¼‰
- æ¯ä¸ª index åªèƒ½å‡ºç°ä¸€æ¬¡"""

        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åˆ†ç±»ä¸“å®¶ã€‚"),
            HumanMessage(content=prompt),
        ]

        print("\nğŸ¤” AI æ­£åœ¨åˆ†æä»“åº“å¹¶æ™ºèƒ½åˆ†ç±»...")
        print("â”€" * 60)

        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        for chunk in self.llm.stream(messages):
            content = chunk.content
            print(content, end="", flush=True)
            full_content += content

        print("\n" + "â”€" * 60)

        try:
            # è§£æ LLM è¿”å›çš„åˆ†ç±»ç»“æœ
            result = json.loads(full_content)
            categories_list = result.get("categories", [])

            # ä½¿ç”¨ CategoryNode ç±»è§£æ
            root_nodes = []
            for cat_data in categories_list:
                root_nodes.append(CategoryNode.from_dict(cat_data))

            print(f"\nâœ… AI åˆ†ç±»å®Œæˆï¼Œå…± {len(root_nodes)} ä¸ªé¡¶å±‚åˆ†ç±»")

            # æ„å»ºæ‰å¹³çš„åˆ†ç±»å­—å…¸
            categories = {}
            category_descriptions = {}
            used_indices = set()

            def process_node(node: CategoryNode, parent_path: str = ""):
                """é€’å½’å¤„ç†èŠ‚ç‚¹ï¼ˆä½¿ç”¨ç±»æ–¹æ³•ï¼‰"""
                # æ„å»ºå®Œæ•´è·¯å¾„
                full_path = f"{parent_path} / {node.name}" if parent_path else node.name

                # è¾“å‡ºå±‚çº§ç»“æ„
                depth = len(parent_path.split(" / ")) if parent_path else 0
                indent = "  " * depth
                prefix = "â””â”€ " if depth > 0 else "ğŸ“ "

                if depth == 0:
                    print(f"\n{prefix}{node.name}")
                else:
                    print(f"{indent}{prefix}{node.name}")

                # ä¿å­˜æè¿°
                if node.description:
                    category_descriptions[full_path] = node.description

                # å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹ï¼Œå¤„ç†ä»“åº“
                if node.repos:
                    # å»é‡
                    unique_indices = [idx for idx in node.repos if idx not in used_indices and idx < len(analyze_repos)]

                    if len(unique_indices) != len(node.repos):
                        duplicate_count = len(node.repos) - len(unique_indices)
                        print(f"{indent}   âš ï¸  ç§»é™¤ {duplicate_count} ä¸ªé‡å¤")

                    used_indices.update(unique_indices)

                    if unique_indices:
                        categories[full_path] = [analyze_repos[idx] for idx in unique_indices]
                        print(f"{indent}   ({len(unique_indices)} ä¸ªä»“åº“)")

                # é€’å½’å¤„ç†å­èŠ‚ç‚¹
                for child in node.children:
                    process_node(child, full_path)

            # å¤„ç†æ‰€æœ‰æ ¹èŠ‚ç‚¹
            for root in root_nodes:
                process_node(root)

            # æ£€æŸ¥æ˜¯å¦æœ‰ä»“åº“æœªè¢«åˆ†ç±»
            all_assigned = len(used_indices)
            if all_assigned == 0:
                print("\nâš ï¸  è­¦å‘Š: AI æœªåˆ†é…ä»»ä½•ä»“åº“ï¼Œä½¿ç”¨é»˜è®¤è¯­è¨€åˆ†ç±»")
                categories = self._default_categorize(repos)
                category_descriptions = {}
            elif all_assigned < len(analyze_repos):
                unassigned_count = len(analyze_repos) - all_assigned
                print(f"\nâš ï¸  æ³¨æ„: æœ‰ {unassigned_count} ä¸ªä»“åº“æœªè¢«åˆ†ç±»")

                # å°†æœªåˆ†ç±»çš„ä»“åº“æ·»åŠ åˆ°"å…¶ä»–"åˆ†ç±»
                unassigned_indices = set(range(len(analyze_repos))) - used_indices
                if unassigned_indices:
                    categories["å…¶ä»–"] = [analyze_repos[idx] for idx in unassigned_indices]
                    category_descriptions["å…¶ä»–"] = "æœªæ˜ç¡®åˆ†ç±»çš„é¡¹ç›®"
                    print(f"   å·²è‡ªåŠ¨å½’å…¥ã€Œå…¶ä»–ã€åˆ†ç±»")

            state["categories"] = categories
            state["category_descriptions"] = category_descriptions
            state["messages"].append(AIMessage(content=f"âœ“ å®Œæˆæ™ºèƒ½åˆ†ç±»ï¼Œå…± {len(categories)} ä¸ªåˆ†ç±»"))

        except json.JSONDecodeError as e:
            # å¦‚æœ LLM è¿”å›æ ¼å¼æœ‰è¯¯ï¼Œä½¿ç”¨é»˜è®¤æŒ‰è¯­è¨€åˆ†ç±»
            print(f"\nâš ï¸  è­¦å‘Š: LLM è¿”å›æ ¼å¼é”™è¯¯ ({e})ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»")
            categories = self._default_categorize(repos)
            state["categories"] = categories
            state["category_descriptions"] = {}
            state["messages"].append(AIMessage(content="ä½¿ç”¨é»˜è®¤è¯­è¨€åˆ†ç±»"))

        return state

    def generate_recommendations(self, state: AgentState) -> AgentState:
        """
        ç”Ÿæˆå­¦ä¹ è·¯å¾„å’Œæ¨è

        åˆ†æä»“åº“ç»„åˆï¼Œæä¾›å­¦ä¹ å»ºè®®å’Œé¡¹ç›®æ¨è
        """
        print("\n" + "=" * 70)
        print("ğŸ’¡ æ­¥éª¤ 3/4: ç”Ÿæˆå­¦ä¹ è·¯å¾„å’Œæ¨è")
        print("=" * 70)

        categories = state["categories"]
        repos = state["repositories"]
        print(f"ğŸ“š åŸºäº {len(categories)} ä¸ªåˆ†ç±»ç”Ÿæˆæ¨è...")

        # å‡†å¤‡åˆ†ç±»æ‘˜è¦
        category_summary = {}
        for cat_name, cat_repos in categories.items():
            top_repos = sorted(cat_repos, key=lambda x: x["stars"], reverse=True)[:5]
            category_summary[cat_name] = {
                "count": len(cat_repos),
                "top_projects": [
                    {"name": r["full_name"], "stars": r["stars"]}
                    for r in top_repos
                ],
            }

        prompt = f"""åŸºäºç”¨æˆ·æ”¶è—çš„ GitHub ä»“åº“ï¼Œæä¾›å­¦ä¹ è·¯å¾„å’Œé¡¹ç›®æ¨èã€‚

            åˆ†ç±»æ¦‚è§ˆï¼š
            {json.dumps(category_summary, ensure_ascii=False, indent=2)}
            
            è¯·æä¾›ï¼š
            1. å­¦ä¹ è·¯å¾„å»ºè®®ï¼ˆé’ˆå¯¹ä¸»è¦æŠ€æœ¯æ ˆï¼‰
            2. å…³é”®é¡¹ç›®æ¨èï¼ˆæ ‡æ³¨ä¸º"â­ å¿…çœ‹"ï¼‰
            3. æŠ€æœ¯æ ˆç»„åˆå»ºè®®
            
            è¿”å›æ ¼å¼ï¼ˆMarkdownï¼‰ï¼š
            ### å­¦ä¹ è·¯å¾„
            - **è·¯å¾„1**: æè¿° â†’ æ¨èé¡¹ç›®1 â†’ é¡¹ç›®2 â†’ é¡¹ç›®3
            - **è·¯å¾„2**: ...
            
            ### å…³é”®é¡¹ç›®
            - â­ [é¡¹ç›®åç§°](URL) - æ¨èç†ç”±
            
            ### æŠ€æœ¯æ ˆå»ºè®®
            - ç»„åˆ1ï¼š...
            - ç»„åˆ2ï¼š...
        """

        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯å­¦ä¹ è·¯å¾„è§„åˆ’ä¸“å®¶ã€‚"),
            HumanMessage(content=prompt),
        ]

        print("\nğŸ’¡ AI æ­£åœ¨ç”Ÿæˆå­¦ä¹ è·¯å¾„å’Œæ¨è...")
        print("â”€" * 60)

        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        for chunk in self.llm.stream(messages):
            content = chunk.content
            print(content, end="", flush=True)
            full_content += content

        print("\n" + "â”€" * 60)

        state["recommendations"] = full_content.split("\n")
        state["messages"].append(AIMessage(content="âœ“ ç”Ÿæˆå­¦ä¹ è·¯å¾„å’Œæ¨è"))

        return state

    def generate_markdown(self, state: AgentState) -> AgentState:
        """
        ç”Ÿæˆæœ€ç»ˆçš„ Markdown ç´¢å¼•æ–‡æ¡£
        """
        print("\n" + "=" * 70)
        print("ğŸ“ æ­¥éª¤ 4/4: ç”Ÿæˆ Markdown æ–‡æ¡£")
        print("=" * 70)
        
        categories = state["categories"]
        category_descriptions = state["category_descriptions"]
        recommendations = state["recommendations"]
        repos = state["repositories"]

        md = []
        
        # æ¸²æŸ“å„ä¸ªéƒ¨åˆ†
        self._render_header(md, repos, categories)
        self._render_toc_section(md, categories)
        
        if recommendations:
            self._render_recommendations_section(md, recommendations)
        
        self._render_categories_section(md, categories, category_descriptions)
        self._render_statistics_section(md, repos)
        self._render_footer(md)

        state["markdown_output"] = "\n".join(md)
        state["messages"].append(AIMessage(content="âœ“ Markdown æ–‡æ¡£ç”Ÿæˆå®Œæˆ"))

        print("\nâœ… æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼")
        return state
    
    def _render_header(self, md: List[str], repos: List[Dict], categories: Dict) -> None:
        """æ¸²æŸ“æ–‡æ¡£å¤´éƒ¨"""
        md.append(f"# ğŸŒŸ GitHub Stars æ™ºèƒ½ç´¢å¼•\n")
        md.append(f"> ğŸ“š AI é©±åŠ¨çš„ä¸ªæ€§åŒ–æ”¶è—åº“ | æ›´æ–°æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}\n")
        md.append("## ğŸ“– å…³äº\n")
        md.append(f"- **æ€»æ”¶è—**: {len(repos)} ä¸ªé¡¹ç›®")
        md.append(f"- **æ™ºèƒ½åˆ†ç±»**: {len(categories)} ä¸ªé¢†åŸŸ")
        md.append("- **AI åˆ†æ**: ç”± LangGraph Agent (Qwen) æ™ºèƒ½æ•´ç†\n")
        md.append("---\n")
    
    def _render_toc_section(self, md: List[str], categories: Dict) -> None:
        """æ¸²æŸ“ç›®å½•éƒ¨åˆ†"""
        md.append("## ğŸ“‹ ç›®å½•\n")
        
        # æ„å»ºç›®å½•æ ‘
        toc_tree = self._build_toc_tree(categories)
        
        # é€’å½’æ¸²æŸ“ç›®å½•
        self._render_toc_level(toc_tree, 0, md)
        md.append("\n---\n")
    
    def _render_recommendations_section(self, md: List[str], recommendations: List[str]) -> None:
        """æ¸²æŸ“æ¨èéƒ¨åˆ†"""
        md.append("## ğŸ’¡ AI æ¨è\n")
        md.extend(recommendations)
        md.append("\n---\n")
    
    def _render_categories_section(self, md: List[str], categories: Dict, 
                                     category_descriptions: Dict) -> None:
        """æ¸²æŸ“åˆ†ç±»å†…å®¹éƒ¨åˆ†"""
        # æ„å»ºåˆ†ç±»æ ‘
        category_tree = self._build_category_tree(categories)
        
        # é€’å½’æ¸²æŸ“åˆ†ç±»å†…å®¹
        self._render_category_level(category_tree, 2, md, category_descriptions)
    
    def _render_statistics_section(self, md: List[str], repos: List[Dict]) -> None:
        """æ¸²æŸ“ç»Ÿè®¡åˆ†æéƒ¨åˆ†"""
        md.append("## ğŸ“Š ç»Ÿè®¡åˆ†æ\n")
        
        # ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
        lang_stats = self._calculate_language_stats(repos)
        md.append("### ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ\n")
        for lang, count in list(lang_stats.items())[:8]:
            percentage = (count / len(repos)) * 100
            md.append(f"- **{lang}**: {count} ä¸ª ({percentage:.1f}%)")

        # Stars åˆ†å¸ƒ
        md.append("\n### Stars åˆ†å¸ƒ\n")
        stars_ranges = self._calculate_stars_ranges(repos)
        for range_name, count in stars_ranges.items():
            if count > 0:
                md.append(f"- {range_name}: {count} ä¸ª")

        # Top 10
        md.append("\n### ğŸ† Top 10 æ˜æ˜Ÿé¡¹ç›®\n")
        top_repos = sorted(repos, key=lambda x: x["stars"], reverse=True)[:10]
        for i, repo in enumerate(top_repos, 1):
            stars = self._format_stars(repo["stars"])
            md.append(f"{i}. **{repo['full_name']}** - â­ {stars}")
    
    def _render_footer(self, md: List[str]) -> None:
        """æ¸²æŸ“æ–‡æ¡£åº•éƒ¨"""
        md.append("\n---\n")
        md.append(f"*ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
        md.append(f"*ğŸ¤– ç”± GitHub Stars Agent (Qwen) æ™ºèƒ½ç”Ÿæˆ*")

    # ========================================================================
    # è¾…åŠ©æ–¹æ³• - æ ‘æ„å»º
    # ========================================================================
    
    def _build_toc_tree(self, categories: Dict[str, List[Dict]]) -> Dict:
        """æ„å»ºç›®å½•æ ‘ç»“æ„"""
        toc_tree = {}
        for cat_path, cat_repos in categories.items():
            parts = [p.strip() for p in cat_path.split(" / ")]
            current = toc_tree
            for part in parts:
                if part not in current:
                    current[part] = {"_count": 0, "_children": {}, "_name": part}
                current = current[part]["_children"]
            
            # è®°å½•ä»“åº“æ•°é‡
            if parts:
                parent = toc_tree
                for part in parts[:-1]:
                    parent = parent[part]["_children"]
                parent[parts[-1]]["_count"] = len(cat_repos)
        
        return toc_tree
    
    def _build_category_tree(self, categories: Dict[str, List[Dict]]) -> Dict:
        """æ„å»ºåˆ†ç±»å†…å®¹æ ‘ç»“æ„"""
        category_tree = {}
        for cat_path, cat_repos in categories.items():
            parts = [p.strip() for p in cat_path.split(" / ")]
            
            # å°†è·¯å¾„æ’å…¥æ ‘ä¸­
            current = category_tree
            for i, part in enumerate(parts):
                if part not in current:
                    current[part] = {"_repos": None, "_children": {}, "_path": " / ".join(parts[:i + 1])}
                current = current[part]["_children"]
            
            # æœ€åä¸€çº§ä¿å­˜ä»“åº“
            if parts:
                last_part = parts[-1]
                parent = category_tree
                for part in parts[:-1]:
                    parent = parent[part]["_children"]
                parent[last_part]["_repos"] = cat_repos
        
        return category_tree
    
    # ========================================================================
    # è¾…åŠ©æ–¹æ³• - é€’å½’ç»Ÿè®¡
    # ========================================================================
    
    def _get_all_children(self, tree: Dict) -> List[Dict]:
        """é€’å½’è·å–æ‰€æœ‰å­èŠ‚ç‚¹"""
        result = []
        for node in tree.values():
            result.append(node)
            if node.get("_children"):
                result.extend(self._get_all_children(node["_children"]))
        return result
    
    def _get_all_repos_from_tree(self, tree: Dict) -> List[Dict]:
        """é€’å½’è·å–æ ‘ä¸­æ‰€æœ‰ä»“åº“"""
        total = []
        for node in tree.values():
            if node.get("_repos"):
                total.extend(node["_repos"])
            if node.get("_children"):
                total.extend(self._get_all_repos_from_tree(node["_children"]))
        return total

    def _count_repos_recursive(self, tree: Dict) -> int:
        """é€’å½’ç»Ÿè®¡æ ‘ä¸­æ‰€æœ‰ä»“åº“æ•°é‡"""
        total = 0
        for node in tree.values():
            if node.get("_repos"):
                total += len(node["_repos"])
            if node.get("_children"):
                total += self._count_repos_recursive(node["_children"])
        return total
    
    # ========================================================================
    # è¾…åŠ©æ–¹æ³• - é€’å½’æ¸²æŸ“
    # ========================================================================
    
    def _render_toc_level(self, tree: Dict, depth: int, md: List[str]) -> None:
        """é€’å½’æ¸²æŸ“ç›®å½•ï¼ˆæ”¯æŒä»»æ„å±‚çº§ï¼‰"""
        if not tree:
            return
        
        # æŒ‰æ•°é‡æ’åº
        sorted_items = sorted(
            tree.items(),
            key=lambda x: x[1]["_count"] + sum(
                child["_count"] for child in self._get_all_children(x[1]["_children"])
            ),
            reverse=True
        )
        
        for name, node in sorted_items:
            count = node["_count"]
            children = node["_children"]
            
            # è®¡ç®—æ€»æ•°ï¼ˆåŒ…æ‹¬å­åˆ†ç±»ï¼‰
            total = count + sum(
                child["_count"] for child in self._get_all_children(children)
            )
            
            # ç¼©è¿›
            indent = "  " * depth
            
            # ç”Ÿæˆç›®å½•é¡¹ï¼ˆéƒ½æ˜¾ç¤ºæ€»æ•°ï¼‰
            if depth == 0:
                # é¡¶å±‚åŠ ç²—
                md.append(f"{indent}- **[{name}](#{self._anchor(name)})** ({total}ä¸ª)")
            else:
                # éé¡¶å±‚ä¹Ÿæ˜¾ç¤ºæ€»æ•°
                md.append(f"{indent}- [{name}](#{self._anchor(name)}) ({total}ä¸ª)")
            
            # é€’å½’å­ç›®å½•
            if children:
                self._render_toc_level(children, depth + 1, md)
    
    def _render_category_level(self, tree: Dict, level: int, md: List[str], 
                                 category_descriptions: Dict) -> None:
        """é€’å½’æ¸²æŸ“åˆ†ç±»æ ‘ï¼ˆæ”¯æŒä»»æ„å±‚çº§ï¼‰"""
        if not tree:
            return
        
        # æŒ‰ä»“åº“æ•°é‡æ’åº
        sorted_items = sorted(
            tree.items(),
            key=lambda x: len(x[1]["_repos"]) if x[1]["_repos"] else 
                          len(self._get_all_repos_from_tree(x[1]["_children"])),
            reverse=True
        )
        
        for name, node in sorted_items:
            repos = node["_repos"]
            children = node["_children"]
            full_path = node["_path"]
            
            # è®¡ç®—ä»“åº“æ•°
            direct_count = len(repos) if repos else 0
            children_count = self._count_repos_recursive(children) if children else 0
            total_repos = direct_count + children_count
            
            # æ¸²æŸ“æ ‡é¢˜å’Œæè¿°
            md.extend(self._render_category_header(
                name, level, full_path, category_descriptions,
                total_repos, bool(children), direct_count
            ))
            
            # å¦‚æœæœ‰ä»“åº“ï¼ˆå¶å­èŠ‚ç‚¹ï¼‰ï¼Œæ¸²æŸ“è¡¨æ ¼
            if repos:
                md.extend(self._render_repo_table(repos))
            
            # é€’å½’æ¸²æŸ“å­åˆ†ç±»
            if children:
                self._render_category_level(children, level + 1, md, category_descriptions)
        
        # å¤§ç±»ä¹‹é—´çš„åˆ†éš”çº¿ï¼ˆä»…ä¸€çº§åˆ†ç±»åï¼‰
        if level == 2:
            md.append("---\n")
    
    # ========================================================================
    # è¾…åŠ©æ–¹æ³• - å†…å®¹æ¸²æŸ“
    # ========================================================================
    
    def _render_repo_table(self, repos: List[Dict]) -> List[str]:
        """æ¸²æŸ“ä»“åº“è¡¨æ ¼"""
        lines = [
            "| åç§° | ç®€ä»‹ | Stars | è¯­è¨€ | é“¾æ¥ |",
            "|------|------|-------|------|------|"
        ]

        for repo in sorted(repos, key=lambda x: x["stars"], reverse=True):
            name_col = repo["name"]
            desc = repo["description"][:50] + "..." if len(repo["description"]) > 50 else repo["description"]
            stars = f"â­ {self._format_stars(repo['stars'])}"
            lang = repo["language"]
            url = f"[ğŸ”—]({repo['url']})"
            lines.append(f"| **{name_col}** | {desc} | {stars} | {lang} | {url} |")

        lines.append("")  # ç©ºè¡Œ
        return lines

    def _render_category_header(self, name: str, level: int, full_path: str,
                                category_descriptions: Dict, total_repos: int,
                                has_children: bool, direct_count: int) -> List[str]:
        """æ¸²æŸ“åˆ†ç±»æ ‡é¢˜å’Œæè¿°"""
        lines = []

        # ç”Ÿæˆæ ‡é¢˜
        header = "#" * min(level, 6)
        lines.append(f"{header} {name}\n")

        # æè¿°
        if full_path in category_descriptions:
            lines.append(f"*{category_descriptions[full_path]}*\n")

        # æ˜¾ç¤ºé¡¹ç›®æ•°
        if has_children:
            lines.append(f"å…±æ”¶å½• {total_repos} ä¸ªé¡¹ç›®\n")
        elif direct_count > 0:
            lines.append(f"æ”¶å½• {direct_count} ä¸ªé¡¹ç›®\n")

        return lines

    def _default_categorize(self, repos: List[Dict]) -> Dict[str, List[Dict]]:
        """é»˜è®¤æŒ‰è¯­è¨€åˆ†ç±»"""
        categories = {}
        for repo in repos:
            lang = repo["language"]
            if lang not in categories:
                categories[lang] = []
            categories[lang].append(repo)
        return categories

    def _format_stars(self, count: int) -> str:
        """æ ¼å¼åŒ– stars æ•°é‡"""
        if count < 1000:
            return str(count)
        elif count < 10000:
            return f"{count / 1000:.1f}k"
        else:
            return f"{count / 1000:.1f}k"

    def _anchor(self, text: str) -> str:
        """ç”Ÿæˆ Markdown é”šç‚¹"""
        import re
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[^\w\s-]', '', text)
        return text.lower().replace(" ", "-")

    def _calculate_language_stats(self, repos: List[Dict]) -> Dict[str, int]:
        """è®¡ç®—è¯­è¨€ç»Ÿè®¡"""
        stats = {}
        for repo in repos:
            lang = repo["language"]
            stats[lang] = stats.get(lang, 0) + 1
        return dict(sorted(stats.items(), key=lambda x: x[1], reverse=True))

    def _calculate_stars_ranges(self, repos: List[Dict]) -> Dict[str, int]:
        """è®¡ç®— stars èŒƒå›´ç»Ÿè®¡"""
        return {
            "100k+": len([r for r in repos if r["stars"] >= 100000]),
            "50k-100k": len([r for r in repos if 50000 <= r["stars"] < 100000]),
            "10k-50k": len([r for r in repos if 10000 <= r["stars"] < 50000]),
            "1k-10k": len([r for r in repos if 1000 <= r["stars"] < 10000]),
            "<1k": len([r for r in repos if r["stars"] < 1000]),
        }


# ============================================================================
# Graph æ„å»º
# ============================================================================


def create_github_stars_graph(llm=None):
    """åˆ›å»º GitHub Stars Agent å·¥ä½œæµå›¾"""

    agent = GitHubStarsAgent(llm=llm)

    # åˆ›å»ºå›¾
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("fetch", agent.fetch_github_stars)  # æ–°å¢ï¼šè·å–æ•°æ®
    workflow.add_node("analyze", agent.analyze_repositories)
    # workflow.add_node("recommend", agent.generate_recommendations)
    workflow.add_node("generate", agent.generate_markdown)

    # æ·»åŠ è¾¹
    workflow.add_edge(START, "fetch")  # ä»è·å–æ•°æ®å¼€å§‹
    workflow.add_edge("fetch", "analyze")
    # workflow.add_edge("analyze", "recommend")
    workflow.add_edge("analyze", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()


# ============================================================================
# å…¬å…± API
# ============================================================================


def run_agent(
        github_token: Optional[str] = None,
        username: Optional[str] = None,
        min_stars: int = 0,
        output: str = "stars_index_ai.md",
        llm=None,
) -> Dict:
    """
    è¿è¡Œ GitHub Stars Agent
    
    Args:
        github_token: GitHub Tokenï¼ˆå¦‚æœä¸º Noneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        username: GitHub ç”¨æˆ·åï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨è®¤è¯ç”¨æˆ·ï¼‰
        min_stars: æœ€å° stars æ•°é‡è¿‡æ»¤
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        llm: LLM å®ä¾‹ï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨ Qwen æ¨¡å‹ï¼‰
    
    Returns:
        æœ€ç»ˆçŠ¶æ€å­—å…¸
    """
    # è·å– GitHub Token
    token = github_token or os.environ.get("GITHUB_TOKEN")
    if not token:
        raise ValueError(
            "æœªæä¾› GitHub Token\n"
            "è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æä¾›ï¼š\n"
            "1. è®¾ç½®ç¯å¢ƒå˜é‡: export GITHUB_TOKEN=your_token\n"
            "2. ä¼ é€’å‚æ•°: run_agent(github_token='your_token')\n"
            "\nè·å– Token: https://github.com/settings/tokens"
        )

    # åˆ›å»º Agent å’Œå·¥ä½œæµå›¾
    print("\n" + "â•”" + "=" * 68 + "â•—")
    print("â•‘" + " " * 15 + "ğŸ¤– GitHub Stars AI Agent" + " " * 29 + "â•‘")
    print("â•‘" + " " * 20 + "Powered by Qwen" + " " * 33 + "â•‘")
    print("â•š" + "=" * 68 + "â•")

    graph = create_github_stars_graph(llm=llm)

    # æ‰§è¡Œå·¥ä½œæµ
    print("\nğŸš€ å¼€å§‹æ‰§è¡Œ LangGraph å·¥ä½œæµ...")
    print("   æµç¨‹: fetch â†’ analyze â†’ recommend â†’ generate\n")

    initial_state = {
        "messages": [HumanMessage(content="å¼€å§‹ GitHub Stars æ™ºèƒ½åˆ†æ")],
        "github_token": token,
        "username": username,
        "min_stars": min_stars,
        "repositories": [],
        "categories": {},
        "category_descriptions": {},
        "recommendations": [],
        "markdown_output": "",
    }

    result = graph.invoke(initial_state)

    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ’¾ ä¿å­˜ç»“æœ")
    print("=" * 70)

    markdown = result["markdown_output"]
    with open(output, "w", encoding="utf-8") as f:
        f.write(markdown)

    print(f"\n" + "â•”" + "=" * 68 + "â•—")
    print(f"â•‘  âœ… å®Œæˆï¼ç´¢å¼•å·²ç”Ÿæˆ" + " " * 44 + "â•‘")
    print(f"â•š" + "=" * 68 + "â•")
    print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶: {output}")
    print(f"   - æ€»ä»“åº“: {len(result['repositories'])}")
    print(f"   - åˆ†ç±»æ•°: {len(result['categories'])}")
    print(f"   - ä½¿ç”¨æ¨¡å‹: Qwen")

    # æ‰“å°æ¶ˆæ¯å†å²
    print("\nğŸ“ å¤„ç†æ—¥å¿—:")
    for msg in result["messages"]:
        if isinstance(msg, AIMessage):
            print(f"   {msg.content}")

    return result


# ============================================================================
# CLI å…¥å£
# ============================================================================


def main():
    """å‘½ä»¤è¡Œå…¥å£ï¼ˆå¯é€‰ï¼‰"""
    import argparse

    parser = argparse.ArgumentParser(
        description="GitHub Stars Agent - AI é©±åŠ¨çš„æ™ºèƒ½ç´¢å¼•ç”Ÿæˆï¼ˆä½¿ç”¨ Qwen æ¨¡å‹ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ— å‚æ•°è¿è¡Œï¼ˆä»ç¯å¢ƒå˜é‡è¯»å– GITHUB_TOKENï¼‰
  python github_stars_agent.py
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python github_stars_agent.py --output my_stars.md
  
  # è¿‡æ»¤é«˜è´¨é‡é¡¹ç›®
  python github_stars_agent.py --min-stars 100
  
  # è·å–å…¶ä»–ç”¨æˆ·çš„å…¬å¼€ stars
  python github_stars_agent.py --username other-user
        """
    )
    parser.add_argument(
        "--token",
        type=str,
        help="GitHub Personal Access Token (é»˜è®¤ä» GITHUB_TOKEN ç¯å¢ƒå˜é‡è¯»å–)",
    )
    parser.add_argument(
        "--username",
        type=str,
        help="GitHub ç”¨æˆ·å (é»˜è®¤ä½¿ç”¨è®¤è¯ç”¨æˆ·)",
    )
    parser.add_argument(
        "--min-stars",
        type=int,
        default=0,
        help="æœ€å° stars æ•°é‡è¿‡æ»¤ (é»˜è®¤: 0)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="stars_index_ai.md",
        help="è¾“å‡º Markdown æ–‡ä»¶è·¯å¾„ (é»˜è®¤: stars_index_ai.md)",
    )

    args = parser.parse_args()

    try:
        result = run_agent(
            github_token=args.token,
            username=args.username,
            min_stars=args.min_stars,
            output=args.output,
        )
        return 0

    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯: {e}")
        return 1
    except requests.exceptions.HTTPError as e:
        print(f"âŒ GitHub API é”™è¯¯: {e}")
        if e.response.status_code == 401:
            print("æç¤º: Token å¯èƒ½æ— æ•ˆæˆ–å·²è¿‡æœŸ")
        return 1
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
