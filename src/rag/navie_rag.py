import os
import bs4
from typing import TypedDict, List, Annotated
from dotenv import load_dotenv
from langgraph.graph import StateGraph, START, END
from langchain_qdrant import Qdrant
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.vectorstores import VectorStore
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from ..util import get_qwen_model, get_embedding_model

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½® USER_AGENT
if not os.getenv("USER_AGENT"):
    os.environ["USER_AGENT"] = (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )


# ============ 1. å®šä¹‰çŠ¶æ€ ============
class RagState(TypedDict):
    """RAG å·¥ä½œæµçŠ¶æ€"""

    question: str  # ç”¨æˆ·é—®é¢˜
    retrieved_docs: List[str]  # æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µ
    answer: str  # LLM ç”Ÿæˆçš„ç­”æ¡ˆ


# ============ 2. æ„å»ºå‘é‡çŸ¥è¯†åº“ ============
def build_vectorstore(doc_path: str = "./knowledge.txt") -> VectorStore:
    """åŠ è½½webæ–‡æ¡£"""
    loader = WebBaseLoader(
        web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                class_=("post-content", "post-title", "post-header")
            )
        ),
    )
    docs = loader.load()

    # æ–‡æœ¬åˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    splits = text_splitter.split_documents(docs)

    # åˆ›å»ºå‘é‡åº“
    embeddings = get_embedding_model()
    vectorstore = Qdrant.from_documents(
        splits,
        embeddings,
        location=":memory:",
        collection_name="langgraph_knowledge",
    )
    return vectorstore


# åˆå§‹åŒ–å‘é‡åº“ï¼ˆå…¨å±€å•ä¾‹ï¼‰
vectorstore = build_vectorstore()
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})


# ============ 3. å®šä¹‰èŠ‚ç‚¹å‡½æ•° ============
def retrieve_node(state: RagState) -> RagState:
    """æ£€ç´¢èŠ‚ç‚¹ï¼šæ ¹æ®é—®é¢˜æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
    docs = retriever.invoke(state["question"])
    retrieved_texts = [doc.page_content for doc in docs]
    print(f"ğŸ” æ£€ç´¢åˆ° {len(retrieved_texts)} ä¸ªç›¸å…³ç‰‡æ®µ")
    for i, text in enumerate(retrieved_texts, 1):
        print(f"  [{i}] {text.strip()}")
    return {
        "question": state["question"],
        "retrieved_docs": retrieved_texts,
        "answer": "",  # é‡ç½®ç­”æ¡ˆ
    }


def generate_node(state: RagState) -> RagState:
    """ç”ŸæˆèŠ‚ç‚¹ï¼šåŸºäºé—®é¢˜å’Œæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ"""
    # æ„å»º Prompt
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚"
                "\nä¸Šä¸‹æ–‡ï¼š{context}"
                "\nå¦‚æœä¸Šä¸‹æ–‡æ— æ³•å›ç­”é—®é¢˜ï¼Œè¯·è¯´æ˜ä½ ä¸çŸ¥é“ã€‚",
            ),
            ("human", "{question}"),
        ]
    )

    # æ„å»º RAG Chain
    llm = get_qwen_model()
    rag_chain = (
        {
            "context": lambda x: "\n\n".join(x["retrieved_docs"]),
            "question": lambda x: x["question"],
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    # ç”Ÿæˆç­”æ¡ˆ
    answer = rag_chain.invoke(state)
    print(f"âœ… ç”Ÿæˆç­”æ¡ˆï¼š{answer[:100]}...")
    return {
        "question": state["question"],
        "retrieved_docs": state["retrieved_docs"],
        "answer": answer,
    }


# ============ 4. æ„å»º LangGraph å·¥ä½œæµ ============
def create_rag_graph() -> StateGraph:
    """åˆ›å»ºæœ´ç´  RAG å·¥ä½œæµå›¾"""
    workflow = StateGraph(RagState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("generate", generate_node)

    # å®šä¹‰æ‰§è¡Œæµï¼šSTART â†’ retrieve â†’ generate â†’ END
    workflow.add_edge(START, "retrieve")
    workflow.add_edge("retrieve", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()


# ============ 5. ä½¿ç”¨ç¤ºä¾‹ ============
if __name__ == "__main__":
    # ç¼–è¯‘å›¾
    rag_app = create_rag_graph()

    # ç¤ºä¾‹é—®é¢˜
    questions = [
        "LangGraph æ˜¯ä»€ä¹ˆï¼Ÿ",
        "LangGraph æ”¯æŒå“ªäº›ç‰¹æ€§ï¼Ÿ",
        "å¦‚ä½•ç”¨ LangGraph æ„å»º Agentï¼Ÿ",
    ]

    for q in questions:
        print(f"\n{'=' * 50}")
        print(f"â“ é—®é¢˜: {q}")
        print(f"{'=' * 50}")

        # æ‰§è¡Œ RAG æµç¨‹
        result = rag_app.invoke({"question": q, "retrieved_docs": [], "answer": ""})
